{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from data_cleaning import fill_missing_values, rename_columns\n",
    "from data_science_skript import preprocess_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import optuna\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\kimko\\PortfolioProjekt\\adult.csv\", na_values=[\"?\"]) \n",
    "df = fill_missing_values(df) \n",
    "df = rename_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diskriminierung beim Datensatz\n",
    "\n",
    "plt.style.use(\"dark_background\")  \n",
    "colors = [\"silver\", \"teal\"]\n",
    "\n",
    "# Einkommensverteilung nach Geschlecht\n",
    "income_gender = df.groupby([\"sex\", \"income\"]).size().unstack()\n",
    "income_gender.plot(kind=\"bar\", stacked=True, color = colors, figsize=(8, 5))\n",
    "plt.title(\"Einkommensverteilung nach Geschlecht\")\n",
    "plt.xlabel(\"Geschlecht\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Einkommen\")\n",
    "plt.show()\n",
    "\n",
    "# Einkommensverteilung nach Ethnie\n",
    "income_race = df.groupby([\"race\",\"income\"]).size().unstack()\n",
    "income_race.plot(kind=\"bar\", stacked=True, color = colors, figsize=(10, 5))\n",
    "plt.title(\"Einkommensverteilung nach Ethnie\")\n",
    "plt.xlabel(\"Ethnie\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Einkommen\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic Parity für Geschlecht\n",
    "gender_parity = df[df[\"income\"] == '>50K']['sex'].value_counts(normalize=True)\n",
    "print(gender_parity)\n",
    "\n",
    "# Demographic Parity für Ethnie\n",
    "race_parity = df[df[\"income\"] == '>50K']['race'].value_counts(normalize=True)\n",
    "print(race_parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies deutet auf starke Unterschiede in der Einkommensverteilung hin und muss beim Feature-Engeneering mit beachtet werden\n",
    "- Geschlecht und Ethnie sollte als sensible Merkmale beachtet werden\n",
    "- verschiedene Korkkekturne: Reweightung, Fairness Constraints\n",
    "\n",
    "### Fairness in der Vorhersage messen:\n",
    "- Falsch Positive und Falsch Negativ messen\n",
    "- Disparate Impact Score = Rate der pos Ergebnisse für die benachteiligten Gruppe / Rate der pos Ergebnisse für die bevorzugte Gruppe (>0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellauswahl\n",
    "- Logistisches Modell \n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Neuronale Netze?\n",
    "### Fairness-optimierte Modelle\n",
    "- Fair Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variablen umwandeln\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[\"int64\"])\n",
    "sns.heatmap(df_numeric.corr(),cmap=\"plasma\", vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der Feature-Correlation\n",
    "- education_num\n",
    "- age\n",
    "- sex, hours_per_week, age, income scheinen eine gewisse Korrelation zu haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "target = df[\"income\"]\n",
    "features = df.drop(columns=[\"income\"])\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainingsdaten:\\n\",features_train.shape)\n",
    "print(\"\\nTestdaten:\\n\",features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.countplot(x=target_train, ax=ax[0])\n",
    "ax[0].set_title(\"Klassenverteilung im Training-Set\")\n",
    "\n",
    "sns.countplot(x=target_test, ax=ax[1])\n",
    "ax[1].set_title(\"Klassenverteilung im Test-Set\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crosstab_income = pd.crosstab(index=target_train, columns = \"count\", normalize = \"columns\")\n",
    "test_crosstab_income = pd.crosstab(index=target_test, columns = \"count\", normalize = \"columns\")\n",
    "display(train_crosstab_income)\n",
    "display(test_crosstab_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalssenverteilung\n",
    "Es ist ein deutliches Ungleichgewicht der Zielkategorie zu erkennen:\n",
    "- class_weight = balanced\n",
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorbereitung\n",
    "num_cols = features_train.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols = features_train.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols)\n",
    "])\n",
    "\n",
    "# Baselinemodell Logistische Regression\n",
    "\n",
    "pipeline_log_base = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(class_weight=\"balanced\", random_state = 42))\n",
    "     ])\n",
    "\n",
    "pipeline_log_base.fit(features_train,target_train)\n",
    "target_pred_log_base = pipeline_log_base.predict(features_test)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score(target_test, target_pred_log_base))\n",
    "print(\"Classification report\\n\", classification_report(target_test, target_pred_log_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erste Bewertung \n",
    "Das Modell zeigt eine klare Diskriminierung:\n",
    "\n",
    "### Precision\n",
    "    - Einkommen > 50K werden ungenauer (nur mit 57% Wahrscheinlichkeit richtig vorhergesagt)\n",
    "    --> Diskriminierung gegen zu hoch verdienende ?\n",
    "\n",
    "### Recall\n",
    "    - relativ gut und ausgeglichen\n",
    "\n",
    "### F1-Score\n",
    "    - auch hier werden Hochverdiener deutlich schlechter erkannt\n",
    "\n",
    "### Ursachen:\n",
    "- Datenungleichgewicht\n",
    "- Feature Bias\n",
    "- andere Modelle können eventuell besser unterscheiden (RandomForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Anpassung\n",
    "\n",
    "crit_cols = [\"sex\", \"race\"]\n",
    "features_train_crit = features_train.drop(columns=crit_cols)\n",
    "features_test_crit = features_test.drop(columns=crit_cols)\n",
    "\n",
    "num_cols_crit = features_train_crit.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols_crit = features_train_crit.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "preprocessor_crit = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols_crit),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols_crit)\n",
    "])\n",
    "\n",
    "pipeline_log_base_crit = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_crit),\n",
    "    (\"model\", LogisticRegression(class_weight=\"balanced\", random_state = 42))\n",
    "     ])\n",
    "\n",
    "pipeline_log_base_crit.fit(features_train_crit, target_train)\n",
    "target_pred_log_base_crit = pipeline_log_base_crit.predict(features_test_crit)\n",
    "\n",
    "print(\"LogistischeRegression\\n\", classification_report(target_test, target_pred_log_base_crit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Importance des Base-Line Modells\n",
    "feature_names = list(num_cols) + list(pipeline_log_base.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols))\n",
    "coefficients = pipeline_log_base.named_steps[\"model\"].coef_[0]\n",
    "feature_importance = pd.Series(data = pipeline_log_base.named_steps[\"model\"].coef_[0],\n",
    "                               index = feature_names).sort_values(ascending=False)\n",
    "# Feature Importance OHNE sex and race\n",
    "feature_names_crit = list(num_cols_crit) + list(pipeline_log_base_crit.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols_crit))\n",
    "coefficients_crit = pipeline_log_base_crit.named_steps[\"model\"].coef_[0]\n",
    "feature_importance_crit = pd.Series(data = pipeline_log_base_crit.named_steps[\"model\"].coef_[0],\n",
    "                               index = feature_names_crit).sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10)) \n",
    "feature_importance.head(20).plot(kind='barh', ax = ax[0])\n",
    "feature_importance_crit.head(20).plot(kind='barh', ax = ax[1])\n",
    "\n",
    "ax[0].set_title(\"Feature Importance mit allen Features\")\n",
    "ax[1].set_title(\"Feature Importance ohne 'sex' und 'race'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der Feature-Importance\n",
    "- Herkunftsländer scheinen eine auffällig große Rolle zu spielen\n",
    "- das Geschlecht und die Rasse dafür nicht direkt.\n",
    "- --> es gibt aber andere Metriken, die indirekt auf ein Geschlecht hinweisen(Education, Occupation, Relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_log_base[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_log_base[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_log_base[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für Ethnie\n",
    "\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_log_base[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_log_base[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_log_base[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazit zum ersten Baselinemodell Logistische Regression\n",
    "## Geschlecht\n",
    "\n",
    "#### Leichte Diskriminierung erkennbar:\n",
    "Recall (Female: 74,7%, Male: 86,7%)\n",
    "- Frauen, die tatsächlich Hochverdiener sind, werden schlechter erkannt (niedrigerer Recall)\n",
    "- Männer haben einen höheren Recall, das heißt Männer werden besser als Hochverdiener erkannt\n",
    "\n",
    "Accuracy (Female: 91,3%, Male: 75,6%):\n",
    "- Frauen werden besser klassifiziert als Männer:\n",
    "    - die meisten Frauen sind in der Kategorie <=50K\n",
    "    - weitere Features deuten auf Frauen hin (Relationship)\n",
    "\n",
    "Precision (Female: 59,8%, Male: 56,4%):\n",
    "- Ergebnisse sind sehr ähnlich\n",
    "\n",
    "## Ethnie\n",
    "- Das Modell erkennt Hochverdiener aus bestimmten ethnischen Gruppen schlechter:\n",
    "    - Recall für White besonders gut (85,8%) im Gegensatz zu indigenen und \"other\"\n",
    "    - Precision für Indigene besonders schlecht\n",
    "    -Precision für Other extrem gut - Datenset-Problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree\n",
    "# Modell\n",
    "pipeline_dt = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", DecisionTreeClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_dt.fit(features_train, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_dt = pipeline_dt.predict(features_test)\n",
    "\n",
    "#Kennzahlen\n",
    "print(\"DecisionTree:\\n\", classification_report(target_test, target_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "# Modell\n",
    "pipeline_rf = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_rf.fit(features_train, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_rf = pipeline_rf.predict(features_test)\n",
    "\n",
    "#Kennzahlen\n",
    "print(\"RandomForest:\\n\", classification_report(target_test, target_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_names = list(num_cols) + list(pipeline_rf.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols))\n",
    "\n",
    "# Für den DecisionTree\n",
    "feature_importance_dt = pd.Series(data=pipeline_dt.named_steps[\"model\"].feature_importances_,\n",
    "                               index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#RandomForest\n",
    "feature_importance_rf = pd.Series(data=pipeline_rf.named_steps[\"model\"].feature_importances_,\n",
    "                               index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10)) \n",
    "feature_importance_dt.head(20).plot(kind='barh', ax = ax[0])\n",
    "feature_importance_rf.head(20).plot(kind='barh', ax = ax[1])\n",
    "\n",
    "ax[0].set_title(\"Feature Importance Decision Tree\")\n",
    "ax[1].set_title(\"Feature Importance Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für DecisionTree\n",
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "print(\"DecisionTree\")\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_dt[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_dt[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_dt[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_dt[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_dt[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_dt[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für RandomForest\n",
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "print(\"RandomForest\")\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_rf[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_rf[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_rf[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_rf[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_rf[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_rf[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LogisticRegression:\\n\", accuracy_score(target_test, target_pred_log_base), precision_score(target_test, target_pred_log_base), recall_score(target_test, target_pred_log_base))\n",
    "print(\"DecisionTree:\\n\", accuracy_score(target_test, target_pred_dt), precision_score(target_test, target_pred_dt), recall_score(target_test, target_pred_dt))\n",
    "print(\"RandomForest:\\n\", accuracy_score(target_test, target_pred_rf), precision_score(target_test, target_pred_rf), recall_score(target_test, target_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der einzelnen Basismodelle\n",
    "|Modell | Accuracy | Precision | Recall|\n",
    "|:------|:---------|:----------|:------|\n",
    "|Logistische Regression|0.808|0.568|0.848|\n",
    "|DecisionTree|0.815|0.619|0.605|\n",
    "|RandomForest|0.856|0.748|0.607|\n",
    "\n",
    "Aufgrund dieser Werte werde ich mich weiter dem RandomForest widmen, da dies die zuverlässigsten Ergebnisse liefert (hohe Precision) und hohe Gesamtgenauigkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung von SMOTE, um den Bias weiter zu reduzieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf_smote = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"smote\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_rf_smote.fit(features_train, target_train)\n",
    "\n",
    "target_pred_rf_smote = pipeline_rf_smote.predict(features_test)\n",
    "\n",
    "print(\"Classification Report Random Forest with SMOTE:\\n\", classification_report(target_test, target_pred_rf_smote))\n",
    "print(\"RandomForest mit SMOTE:\\n\", accuracy_score(target_test, target_pred_rf_smote), precision_score(target_test, target_pred_rf_smote), recall_score(target_test, target_pred_rf_smote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bewertung SMOTE\n",
    "|Modell | Accuracy | Precision | Recall|\n",
    "|:------|:---------|:----------|:------|\n",
    "|RandomForest|0.856|0.748|0.607|\n",
    "|RandomForest SMOTE|0.845|0.675|0.688|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für RandomForest\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für RandomForest mit SMOTE\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_smote,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_smote,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für DecisionTree\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_dt,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_dt,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für Logistische Regression\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_log_base,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_log_base,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für RandomForest\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für RandomForest mit SMOTE\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_smote, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_smote, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für DecisionTree\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_dt, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_dt, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für LogistischeRegression\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_log_base, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_log_base, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optimization of the RandomForest Hyperparameter\"\"\"\n",
    "\n",
    "    #Searchspace\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 250)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\"])\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10, step=2)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 4)\n",
    "\n",
    "    #Model\n",
    "    params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_features\": max_features,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf\n",
    "    }\n",
    "\n",
    "    model_rf = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **params)\n",
    "\n",
    "    num_cols = features_train.select_dtypes(include=[\"int64\"]).columns\n",
    "    cat_cols = features_train.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model_rf)\n",
    "    ])\n",
    "\n",
    "    score = cross_val_score(\n",
    "        estimator=pipeline, \n",
    "        X=features_train, \n",
    "        y=target_train, \n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=3,\n",
    "        n_jobs=1\n",
    "    ).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# create a study and setting a seed for reproduceability\n",
    "study = optuna.create_study(sampler=TPESampler(seed=42), direction='maximize')\n",
    "\n",
    "# perform hyperparameter tuning\n",
    "time_start = time.time()\n",
    "\n",
    "# starting optimization process with our defined function \n",
    "study.optimize(objective, n_trials=20)\n",
    "time_bayesian = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_bayesian = [\n",
    "    20, \n",
    "    study.best_trial.number, \n",
    "    study.best_trial.value, \n",
    "    time_bayesian\n",
    "]\n",
    "\n",
    "results_bayesian = pd.DataFrame([values_bayesian], columns=[\n",
    "    \"Number of iterations\", \n",
    "    \"Iteration Number of Optimal Hyperparameters\", \n",
    "    \"Score\", \n",
    "    \"Time Elapsed (s)\"\n",
    "])\n",
    "\n",
    "# best hyperparameter\n",
    "print(\"\\nBeste Hyperparameter für Random Forest:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "# show results\n",
    "print(\"\\nOptimierungsergebnisse:\")\n",
    "print(results_bayesian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Hyperparameter\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "model_rf_ba = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **best_params)\n",
    "pipeline_rf_ba = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", model_rf_ba)\n",
    "])\n",
    "\n",
    "pipeline_rf_ba.fit(features_train, target_train)\n",
    "target_pred_rf_ba = pipeline_rf_ba.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken\n",
    "# Fairness-Metriken Equalized Odds Difference für Logistische Regression\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_ba,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_ba,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")\n",
    "\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_ba, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_ba, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ohne die Spalte fnlwgt für RandomForest\n",
    "# Features:\n",
    "features_train_mod = features_train.drop(\"fnlwgt\", axis=1)\n",
    "features_test_mod = features_test.drop(\"fnlwgt\", axis=1)\n",
    "\n",
    "# preprocessor\n",
    "num_cols_mod = features_train_mod.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols_mod = features_train_mod.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "preprocessor_mod = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols_mod),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols_mod)\n",
    "])\n",
    "# Modell\n",
    "pipeline_rf_mod = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_mod),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_rf_mod.fit(features_train_mod, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_rf_mod = pipeline_rf_mod.predict(features_test_mod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optimization of the RandomForest Hyperparameter\"\"\"\n",
    "\n",
    "    #Searchspace\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 250)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\"])\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10, step=2)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 4)\n",
    "\n",
    "    #Model\n",
    "    params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_features\": max_features,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf\n",
    "    }\n",
    "\n",
    "    model_rf_mod = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **params)\n",
    "\n",
    "    num_cols_mod = features_train_mod.select_dtypes(include=[\"int64\"]).columns\n",
    "    cat_cols_mod = features_train_mod.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "    preprocessor_mod = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_cols_mod),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_mod)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    pipeline_mod = Pipeline([\n",
    "        (\"preprocessor\", preprocessor_mod),\n",
    "        (\"model\", model_rf_mod)\n",
    "    ])\n",
    "\n",
    "    score = cross_val_score(\n",
    "        estimator=pipeline_mod, \n",
    "        X=features_train_mod, \n",
    "        y=target_train, \n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=3,\n",
    "        n_jobs=1\n",
    "    ).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# create a study and setting a seed for reproduceability\n",
    "study = optuna.create_study(sampler=TPESampler(seed=42), direction='maximize')\n",
    "\n",
    "# perform hyperparameter tuning\n",
    "time_start = time.time()\n",
    "\n",
    "# starting optimization process with our defined function \n",
    "study.optimize(objective, n_trials=20)\n",
    "time_bayesian = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_bayesian = [\n",
    "    20, \n",
    "    study.best_trial.number, \n",
    "    study.best_trial.value, \n",
    "    time_bayesian\n",
    "]\n",
    "\n",
    "results_bayesian = pd.DataFrame([values_bayesian], columns=[\n",
    "    \"Number of iterations\", \n",
    "    \"Iteration Number of Optimal Hyperparameters\", \n",
    "    \"Score\", \n",
    "    \"Time Elapsed (s)\"\n",
    "])\n",
    "\n",
    "# best hyperparameter\n",
    "print(\"\\nBeste Hyperparameter für Random Forest:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "# show results\n",
    "print(\"\\nOptimierungsergebnisse:\")\n",
    "print(results_bayesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_mod = study.best_params\n",
    "\n",
    "model_rf_ba_mod = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **best_params)\n",
    "pipeline_rf_ba_mod = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_mod),\n",
    "    (\"model\", model_rf_ba_mod)\n",
    "])\n",
    "\n",
    "pipeline_rf_ba_mod.fit(features_train_mod, target_train)\n",
    "target_pred_rf_ba_mod = pipeline_rf_ba_mod.predict(features_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_target_list = [target_pred_log_base, target_pred_dt, target_pred_rf, target_pred_rf_ba, target_pred_rf_mod, target_pred_rf_ba_mod]\n",
    "model_name = [\"LogisticRegression\", \"DecisionTree\", \"RandomForest\", \"RandomForestBaysian\", \"Modifizierter RandomForest\", \"Modifizierter RandomForestBaysian\"]\n",
    "mod_qual = []\n",
    "\n",
    "for target in pred_target_list:\n",
    "    precision = precision_score(target_test, target)\n",
    "    recall = recall_score(target_test, target)\n",
    "    f1 = f1_score(target_test, target)\n",
    "    roc_auc = roc_auc_score(target_test, target)\n",
    "    \n",
    "    mask = features_test[\"sex\"] == 1\n",
    "    roc_auc_male = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"sex\"] == 0\n",
    "    roc_auc_female = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] == \"White\"\n",
    "    roc_auc_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] != \"White\"\n",
    "    roc_auc_Non_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "    eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "    di_sex = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"sex\"]\n",
    "    )\n",
    "    \n",
    "    di_race = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"race\"]\n",
    "    )\n",
    "\n",
    "    dp_diff_sex = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "    dp_diff_race = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"race\"])\n",
    "    \n",
    "    mod_qual.append({\n",
    "                    \"precision\": (precision*100), \"recall\": (recall*100), \"f1\":(f1*100), \"ROC-AUC\": (roc_auc*100),\n",
    "                    \"ROC-AUC-Male\": (roc_auc_male*100),\n",
    "                    \"ROC-AUC-Female\": (roc_auc_female*100),\n",
    "                    \"ROC-AUC-White\": (roc_auc_White*100),\n",
    "                    \"ROC-AUC-Non-White\": (roc_auc_Non_White*100),\n",
    "                    \"EOD 'sex'\": (eq_odds_diff_sex),\n",
    "                    \"EOD 'race'\": (eq_odds_diff_race),\n",
    "                    \"DI 'sex'\": (di_sex),\n",
    "                    \"DI 'race'\": (di_race),\n",
    "                    \"DPD 'sex'\": (dp_diff_sex),\n",
    "                    \"DPD 'race'\": (dp_diff_race)\n",
    "                    })\n",
    "    \n",
    "df_mod_qual = pd.DataFrame(mod_qual, index=model_name)\n",
    "df_mod_qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bewertung\n",
    "1. Wichtigste Erkenntnisse aus den Fairness-Metriken:\n",
    "- DecisionTree ist am fairsten für \"race\", hat aber die schlechteste ROC-AUC (74.71)\n",
    "- RandomForest ist am fairsten für \"sex\", zeigt aber eine starke Diskriminierung für \"race\"\n",
    "- Logistic Regression und Bayesian-Modelle sind die am stärksten diskriminierenden Modelle.\n",
    "- Der Modifizierte RandomForest bietet eine gute Balance zwischen Fairness und Performance.\n",
    "\n",
    "2. Abwägung zwischen Fairness und Performance\n",
    "- Höchste Performance: RandomForestBayesian (83.03 ROC-AUC), aber hohe Diskriminierung.\n",
    "- Fairstes Modell für \"race\": DecisionTree, aber schwache Performance.\n",
    "- Fairstes Modell für \"sex\": RandomForest.\n",
    "- Bester Kompromiss: Modifizierter RandomForest (gute Balance zwischen Fairness und Leistung).\n",
    "\n",
    "3. VWeiterführung:\n",
    "- Fainess-Korrekturen an dem optimierten RandomForest \n",
    "    - Reweighing (durch die Spalte \"fnlwgt\") bereits implementiert\n",
    "    - In-Processing-Techniken: Fainess Constraints \n",
    "    - Post-Processing: Fainess-Korrektur\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "\n",
    "# RandomForest mit einer Fairness-Beschränkung\n",
    "constraint = DemographicParity()  # Alternativ: EqualizedOdds() -> würde noch länger laufen\n",
    "fair_model_rf = ExponentiatedGradient(RandomForestClassifier(n_estimators=100, random_state=42), constraints=constraint)\n",
    "\n",
    "# Preprocessor\n",
    "X_train_processed = preprocessor.fit_transform(features_train)\n",
    "X_train_processed = X_train_processed.toarray()\n",
    "\n",
    "X_test_processed = preprocessor.transform(features_test)\n",
    "X_test_processed = X_test_processed.toarray()\n",
    "\n",
    "# Trainiere das Modell\n",
    "fair_model_rf.fit(X_train_processed, target_train, sensitive_features=features_train[[\"sex\", \"race\"]])\n",
    "\n",
    "# Vorhersagen\n",
    "target_pred_fair_rf = fair_model_rf.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistische Regression mit einer Fairness-Beschränkung\n",
    "constraint = DemographicParity()  # Alternativ: EqualizedOdds()\n",
    "fair_model_log = ExponentiatedGradient(LogisticRegression(max_iter=1000, random_state=42), constraints=constraint)\n",
    "\n",
    "# Preprocessor -> wurde bereits durchgeführt\n",
    "\n",
    "# Trainiere das Modell\n",
    "fair_model_log.fit(X_train_processed, target_train, sensitive_features=features_train[[\"sex\", \"race\"]])\n",
    "\n",
    "# Vorhersagen\n",
    "target_pred_fair_log = fair_model_log.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_target_list_fair = [target_pred_log_base, target_pred_fair_log, target_pred_rf, target_pred_rf_ba, target_pred_fair_rf]\n",
    "model_name = [\"LogisticRegression\", \"Faire LogiticRegression\", \"RandomForest\", \"RandomForestBaysian\", \"Fairer RandomForest\"]\n",
    "mod_qual = []\n",
    "\n",
    "for target in pred_target_list_fair:\n",
    "    precision = precision_score(target_test, target)\n",
    "    recall = recall_score(target_test, target)\n",
    "    f1 = f1_score(target_test, target)\n",
    "    roc_auc = roc_auc_score(target_test, target)\n",
    "    \n",
    "    mask = features_test[\"sex\"] == 1\n",
    "    roc_auc_male = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"sex\"] == 0\n",
    "    roc_auc_female = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] == \"White\"\n",
    "    roc_auc_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] != \"White\"\n",
    "    roc_auc_Non_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "    eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "    di_sex = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"sex\"]\n",
    "    )\n",
    "    \n",
    "    di_race = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"race\"]\n",
    "    )\n",
    "\n",
    "    dp_diff_sex = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "    dp_diff_race = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"race\"])\n",
    "    \n",
    "    mod_qual.append({\n",
    "                    \"precision\": (precision*100), \"recall\": (recall*100), \"f1\":(f1*100), \"ROC-AUC\": (roc_auc*100),\n",
    "                    \"ROC-AUC-Male\": (roc_auc_male*100),\n",
    "                    \"ROC-AUC-Female\": (roc_auc_female*100),\n",
    "                    \"ROC-AUC-White\": (roc_auc_White*100),\n",
    "                    \"ROC-AUC-Non-White\": (roc_auc_Non_White*100),\n",
    "                    \"EOD 'sex'\": (eq_odds_diff_sex),\n",
    "                    \"EOD 'race'\": (eq_odds_diff_race),\n",
    "                    \"DI 'sex'\": (di_sex),\n",
    "                    \"DI 'race'\": (di_race),\n",
    "                    \"DPD 'sex'\": (dp_diff_sex),\n",
    "                    \"DPD 'race'\": (dp_diff_race)\n",
    "                    })\n",
    "    \n",
    "df_mod_qual = pd.DataFrame(mod_qual, index=model_name)\n",
    "df_mod_qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung nach Fairness Constraints\n",
    "1. Fairness-Verbesserung\n",
    "- Logistische Regression\n",
    "    - EOD-Werte gesunken für \"race\", aber leicht gestiegen für \"sex\".\n",
    "    - Disparate Impact (DI) hat sich stark verbessert → von 0.277 auf 0.838 (für \"sex\") und 0.375 auf 0.655 (für \"race\").\n",
    "    - DPD-Werte sind stark gesunken, was bedeutet, dass das Modell jetzt deutlich fairere Vorhersageverteilungen macht.\n",
    "    FAZIT: Starke Verbesserung der Fairness, aber auf Kosten der Performance.\n",
    "- RandomForest\n",
    "    - OD-Werte haben sich verbessert (besonders für \"race\", von 0.464 auf 0.363).\n",
    "    - Disparate Impact (DI) ist fast perfekt für \"sex\" (0.9487) und stark verbessert für \"race\" (0.7839).\n",
    "    - DPD-Werte sind extrem gesunken, also kaum noch Unterschiede in den positiven Vorhersagen.\n",
    "    FAZIT: Beste Fairness-Verbesserung mit minimalem Performance-Verlust!\n",
    "\n",
    "2. Performance-Verlust durch Fairness-Optimierung\n",
    "- Logistic Regression:\n",
    "    - ROC-AUC ist stark gesunken von 82.51 auf 71.98 → Bedeutender Verlust an Modellqualität.\n",
    "    - Precision ist gestiegen, aber Recall ist stark gefallen → Das Modell ist nun sehr konservativ mit positiven Vorhersagen.\n",
    "    FAZIT: Starke Fairness-Verbesserung, aber das Modell ist insgesamt schwächer.\n",
    "\n",
    "- Random Forest:\n",
    "    - ROC-AUC hat sich nur leicht verschlechtert (77.19 → 73.91).\n",
    "    - Precision hat stark gelitten (73.16 → 55.32), aber Recall ist leicht gestiegen.\n",
    "    FAZIT: Besserer Trade-off zwischen Fairness und Leistung als Logistic Regression.\n",
    "\n",
    "Fairer Random Forest ist der beste Kompromiss zwischen Fairness und Modellqualität."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test, ob Postprocessing weiter die Fairness beeinflusst\n",
    "\n",
    "# Threshold Optimizer mit Demographic Parity\n",
    "postprocess_model = ThresholdOptimizer(\n",
    "    estimator=fair_model_rf,  \n",
    "    constraints=\"demographic_parity\",  # Alternativ: \"equalized_odds\"\n",
    "    prefit=True  # Modell ist schon trainiert\n",
    ")\n",
    "\n",
    "# Trainiere den Postprocessor\n",
    "postprocess_model.fit(X_train_processed, target_train, sensitive_features=features_train[[\"sex\", \"race\"]])\n",
    "\n",
    "# Berechne faire Vorhersagen\n",
    "target_pred_fair_rf_post = postprocess_model.predict(X_test_processed, sensitive_features=features_test[[\"sex\", \"race\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold Optimizer mit Demographic Parity\n",
    "postprocess_model_eq = ThresholdOptimizer(\n",
    "    estimator=fair_model_rf,  \n",
    "    constraints=\"equalized_odds\",  \n",
    "    prefit=True \n",
    ")\n",
    "\n",
    "# Trainiere den Postprocessor\n",
    "postprocess_model_eq.fit(X_train_processed, target_train, sensitive_features=features_train[[\"sex\", \"race\"]])\n",
    "\n",
    "# Berechne faire Vorhersagen\n",
    "target_pred_fair_rf_post_eq = postprocess_model.predict(X_test_processed, sensitive_features=features_test[[\"sex\", \"race\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_target_list_fair = [target_pred_rf, target_pred_rf_ba, target_pred_fair_rf, target_pred_fair_rf_post, target_pred_fair_rf_post_eq]\n",
    "model_name = [\"RandomForest\", \"RandomForestBaysian\", \"Fairer RandomForest\", \"Fairer RandomForest Postprocessing\", \"Fairer RandomForest Postprocessing_Eq\"]\n",
    "mod_qual = []\n",
    "\n",
    "for target in pred_target_list_fair:\n",
    "    precision = precision_score(target_test, target)\n",
    "    recall = recall_score(target_test, target)\n",
    "    f1 = f1_score(target_test, target)\n",
    "    roc_auc = roc_auc_score(target_test, target)\n",
    "    \n",
    "    mask = features_test[\"sex\"] == 1\n",
    "    roc_auc_male = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"sex\"] == 0\n",
    "    roc_auc_female = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] == \"White\"\n",
    "    roc_auc_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] != \"White\"\n",
    "    roc_auc_Non_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "    eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "    di_sex = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"sex\"]\n",
    "    )\n",
    "    \n",
    "    di_race = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"race\"]\n",
    "    )\n",
    "\n",
    "    dp_diff_sex = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "    dp_diff_race = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"race\"])\n",
    "    \n",
    "    mod_qual.append({\n",
    "                    \"precision\": (precision*100), \"recall\": (recall*100), \"f1\":(f1*100), \"ROC-AUC\": (roc_auc*100),\n",
    "                    \"ROC-AUC-Male\": (roc_auc_male*100),\n",
    "                    \"ROC-AUC-Female\": (roc_auc_female*100),\n",
    "                    \"ROC-AUC-White\": (roc_auc_White*100),\n",
    "                    \"ROC-AUC-Non-White\": (roc_auc_Non_White*100),\n",
    "                    \"EOD 'sex'\": (eq_odds_diff_sex),\n",
    "                    \"EOD 'race'\": (eq_odds_diff_race),\n",
    "                    \"DI 'sex'\": (di_sex),\n",
    "                    \"DI 'race'\": (di_race),\n",
    "                    \"DPD 'sex'\": (dp_diff_sex),\n",
    "                    \"DPD 'race'\": (dp_diff_race)\n",
    "                    })\n",
    "    \n",
    "df_mod_qual = pd.DataFrame(mod_qual, index=model_name)\n",
    "df_mod_qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung\n",
    "Equalized Odds ist die beste Fairness-Korrektur für \"race\" (EOD stark verbessert von 0.7143 auf 0.2230).\n",
    "Hinsichtlich Performance nur geringe Einbuße durch Postprocessing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDos:\n",
    "Visualisierung der Metriken\n",
    "Aufräumen\n",
    "\n",
    "Vergleich mit LangChain\n",
    "\n",
    "Projekt-Struktur weiter aufbauen\n",
    "\n",
    "optional: neuronales Netz\n",
    "Claude Code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
