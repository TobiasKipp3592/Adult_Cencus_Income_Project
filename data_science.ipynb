{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from data_cleaning import fill_missing_values, rename_columns\n",
    "from data_science_skript import preprocess_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import optuna\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import demographic_parity_difference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Kimi\\Arbeit\\Weiterbildung DADS\\Stackfuel\\Portfolio\\PortfolioProject\\.data\\adult.csv\", na_values=[\"?\"]) \n",
    "df = fill_missing_values(df) \n",
    "df = rename_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diskriminierung beim Datensatz\n",
    "\n",
    "plt.style.use(\"dark_background\")  \n",
    "colors = [\"silver\", \"teal\"]\n",
    "\n",
    "# Einkommensverteilung nach Geschlecht\n",
    "income_gender = df.groupby([\"sex\", \"income\"]).size().unstack()\n",
    "income_gender.plot(kind=\"bar\", stacked=True, color = colors, figsize=(8, 5))\n",
    "plt.title(\"Einkommensverteilung nach Geschlecht\")\n",
    "plt.xlabel(\"Geschlecht\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Einkommen\")\n",
    "plt.show()\n",
    "\n",
    "# Einkommensverteilung nach Ethnie\n",
    "income_race = df.groupby([\"race\",\"income\"]).size().unstack()\n",
    "income_race.plot(kind=\"bar\", stacked=True, color = colors, figsize=(10, 5))\n",
    "plt.title(\"Einkommensverteilung nach Ethnie\")\n",
    "plt.xlabel(\"Ethnie\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Einkommen\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic Parity für Geschlecht\n",
    "gender_parity = df[df[\"income\"] == '>50K']['sex'].value_counts(normalize=True)\n",
    "print(gender_parity)\n",
    "\n",
    "# Demographic Parity für Ethnie\n",
    "race_parity = df[df[\"income\"] == '>50K']['race'].value_counts(normalize=True)\n",
    "print(race_parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies deutet auf starke Unterschiede in der Einkommensverteilung hin und muss beim Feature-Engeneering mit beachtet werden\n",
    "- Geschlecht und Ethnie sollte als sensible Merkmale beachtet werden\n",
    "- verschiedene Korkkekturne: Reweightung, Fairness Constraints\n",
    "\n",
    "### Fairness in der Vorhersage messen:\n",
    "- Falsch Positive und Falsch Negativ messen\n",
    "- Disparate Impact Score = Rate der pos Ergebnisse für die benachteiligten Gruppe / Rate der pos Ergebnisse für die bevorzugte Gruppe (>0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellauswahl\n",
    "- Logistisches Modell \n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Neuronale Netze?\n",
    "### Fairness-optimierte Modelle\n",
    "- Fair Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variablen umwandeln\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[\"int64\"])\n",
    "sns.heatmap(df_numeric.corr(),cmap=\"plasma\", vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der Feature-Correlation\n",
    "- education_num\n",
    "- age\n",
    "- sex, hours_per_week, age, income scheinen eine gewisse Korrelation zu haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "target = df[\"income\"]\n",
    "features = df.drop(columns=[\"income\"])\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainingsdaten:\\n\",features_train.shape)\n",
    "print(\"\\nTestdaten:\\n\",features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.countplot(x=target_train, ax=ax[0])\n",
    "ax[0].set_title(\"Klassenverteilung im Training-Set\")\n",
    "\n",
    "sns.countplot(x=target_test, ax=ax[1])\n",
    "ax[1].set_title(\"Klassenverteilung im Test-Set\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crosstab_income = pd.crosstab(index=target_train, columns = \"count\", normalize = \"columns\")\n",
    "test_crosstab_income = pd.crosstab(index=target_test, columns = \"count\", normalize = \"columns\")\n",
    "display(train_crosstab_income)\n",
    "display(test_crosstab_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalssenverteilung\n",
    "Es ist ein deutliches Ungleichgewicht der Zielkategorie zu erkennen:\n",
    "- class_weight = balanced\n",
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8093044679871028\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.86      4945\n",
      "           1       0.57      0.85      0.68      1568\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.76      0.82      0.77      6513\n",
      "weighted avg       0.85      0.81      0.82      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vorbereitung\n",
    "num_cols = features_train.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols = features_train.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols)\n",
    "])\n",
    "\n",
    "# Baselinemodell Logistische Regression\n",
    "\n",
    "pipeline_log_base = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(class_weight=\"balanced\", random_state = 42))\n",
    "     ])\n",
    "\n",
    "pipeline_log_base.fit(features_train,target_train)\n",
    "target_pred_log_base = pipeline_log_base.predict(features_test)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score(target_test, target_pred_log_base))\n",
    "print(\"Classification report\\n\", classification_report(target_test, target_pred_log_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erste Bewertung \n",
    "Das Modell zeigt eine klare Diskriminierung:\n",
    "\n",
    "### Precision\n",
    "    - Einkommen > 50K werden ungenauer (nur mit 57% Wahrscheinlichkeit richtig vorhergesagt)\n",
    "    --> Diskriminierung gegen zu hoch verdienende ?\n",
    "\n",
    "### Recall\n",
    "    - relativ gut und ausgeglichen\n",
    "\n",
    "### F1-Score\n",
    "    - auch hier werden Hochverdiener deutlich schlechter erkannt\n",
    "\n",
    "### Ursachen:\n",
    "- Datenungleichgewicht\n",
    "- Feature Bias\n",
    "- andere Modelle können eventuell besser unterscheiden (RandomForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Anpassung\n",
    "\n",
    "crit_cols = [\"sex\", \"race\"]\n",
    "features_train_crit = features_train.drop(columns=crit_cols)\n",
    "features_test_crit = features_test.drop(columns=crit_cols)\n",
    "\n",
    "num_cols_crit = features_train_crit.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols_crit = features_train_crit.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "preprocessor_crit = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols_crit),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols_crit)\n",
    "])\n",
    "\n",
    "pipeline_log_base_crit = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_crit),\n",
    "    (\"model\", LogisticRegression(class_weight=\"balanced\", random_state = 42))\n",
    "     ])\n",
    "\n",
    "pipeline_log_base_crit.fit(features_train_crit, target_train)\n",
    "target_pred_log_base_crit = pipeline_log_base_crit.predict(features_test_crit)\n",
    "\n",
    "print(\"LogistischeRegression\\n\", classification_report(target_test, target_pred_log_base_crit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Importance des Base-Line Modells\n",
    "feature_names = list(num_cols) + list(pipeline_log_base.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols))\n",
    "coefficients = pipeline_log_base.named_steps[\"model\"].coef_[0]\n",
    "feature_importance = pd.Series(data = pipeline_log_base.named_steps[\"model\"].coef_[0],\n",
    "                               index = feature_names).sort_values(ascending=False)\n",
    "# Feature Importance OHNE sex and race\n",
    "feature_names_crit = list(num_cols_crit) + list(pipeline_log_base_crit.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols_crit))\n",
    "coefficients_crit = pipeline_log_base_crit.named_steps[\"model\"].coef_[0]\n",
    "feature_importance_crit = pd.Series(data = pipeline_log_base_crit.named_steps[\"model\"].coef_[0],\n",
    "                               index = feature_names_crit).sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10)) \n",
    "feature_importance.head(20).plot(kind='barh', ax = ax[0])\n",
    "feature_importance_crit.head(20).plot(kind='barh', ax = ax[1])\n",
    "\n",
    "ax[0].set_title(\"Feature Importance mit allen Features\")\n",
    "ax[1].set_title(\"Feature Importance ohne 'sex' und 'race'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der Feature-Importance\n",
    "- Herkunftsländer scheinen eine auffällig große Rolle zu spielen\n",
    "- das Geschlecht und die Rasse dafür nicht direkt.\n",
    "- --> es gibt aber andere Metriken, die indirekt auf ein Geschlecht hinweisen(Education, Occupation, Relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_log_base[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_log_base[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_log_base[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für Ethnie\n",
    "\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_log_base[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_log_base[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_log_base[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazit zum ersten Baselinemodell Logistische Regression\n",
    "## Geschlecht\n",
    "\n",
    "#### Leichte Diskriminierung erkennbar:\n",
    "Recall (Female: 74,7%, Male: 86,7%)\n",
    "- Frauen, die tatsächlich Hochverdiener sind, werden schlechter erkannt (niedrigerer Recall)\n",
    "- Männer haben einen höheren Recall, das heißt Männer werden besser als Hochverdiener erkannt\n",
    "\n",
    "Accuracy (Female: 91,3%, Male: 75,6%):\n",
    "- Frauen werden besser klassifiziert als Männer:\n",
    "    - die meisten Frauen sind in der Kategorie <=50K\n",
    "    - weitere Features deuten auf Frauen hin (Relationship)\n",
    "\n",
    "Precision (Female: 59,8%, Male: 56,4%):\n",
    "- Ergebnisse sind sehr ähnlich\n",
    "\n",
    "## Ethnie\n",
    "- Das Modell erkennt Hochverdiener aus bestimmten ethnischen Gruppen schlechter:\n",
    "    - Recall für White besonders gut (85,8%) im Gegensatz zu indigenen und \"other\"\n",
    "    - Precision für Indigene besonders schlecht\n",
    "    -Precision für Other extrem gut - Datenset-Problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      4945\n",
      "           1       0.61      0.61      0.61      1568\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.75      0.75      6513\n",
      "weighted avg       0.81      0.81      0.81      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree\n",
    "# Modell\n",
    "pipeline_dt = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", DecisionTreeClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_dt.fit(features_train, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_dt = pipeline_dt.predict(features_test)\n",
    "\n",
    "#Kennzahlen\n",
    "print(\"DecisionTree:\\n\", classification_report(target_test, target_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      4945\n",
      "           1       0.73      0.62      0.68      1568\n",
      "\n",
      "    accuracy                           0.86      6513\n",
      "   macro avg       0.81      0.78      0.79      6513\n",
      "weighted avg       0.85      0.86      0.85      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "# Modell\n",
    "pipeline_rf = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_rf.fit(features_train, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_rf = pipeline_rf.predict(features_test)\n",
    "\n",
    "#Kennzahlen\n",
    "print(\"RandomForest:\\n\", classification_report(target_test, target_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_names = list(num_cols) + list(pipeline_rf.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols))\n",
    "\n",
    "# Für den DecisionTree\n",
    "feature_importance_dt = pd.Series(data=pipeline_dt.named_steps[\"model\"].feature_importances_,\n",
    "                               index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#RandomForest\n",
    "feature_importance_rf = pd.Series(data=pipeline_rf.named_steps[\"model\"].feature_importances_,\n",
    "                               index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10)) \n",
    "feature_importance_dt.head(20).plot(kind='barh', ax = ax[0])\n",
    "feature_importance_rf.head(20).plot(kind='barh', ax = ax[1])\n",
    "\n",
    "ax[0].set_title(\"Feature Importance Decision Tree\")\n",
    "ax[1].set_title(\"Feature Importance Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für DecisionTree\n",
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "print(\"DecisionTree\")\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_dt[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_dt[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_dt[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_dt[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_dt[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_dt[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für RandomForest\n",
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "print(\"RandomForest\")\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_rf[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_rf[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_rf[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_rf[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_rf[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_rf[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LogisticRegression:\\n\", accuracy_score(target_test, target_pred_log_base), precision_score(target_test, target_pred_log_base), recall_score(target_test, target_pred_log_base))\n",
    "print(\"DecisionTree:\\n\", accuracy_score(target_test, target_pred_dt), precision_score(target_test, target_pred_dt), recall_score(target_test, target_pred_dt))\n",
    "print(\"RandomForest:\\n\", accuracy_score(target_test, target_pred_rf), precision_score(target_test, target_pred_rf), recall_score(target_test, target_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der einzelnen Basismodelle\n",
    "|Modell | Accuracy | Precision | Recall|\n",
    "|:------|:---------|:----------|:------|\n",
    "|Logistische Regression|0.808|0.568|0.848|\n",
    "|DecisionTree|0.815|0.619|0.605|\n",
    "|RandomForest|0.856|0.748|0.607|\n",
    "\n",
    "Aufgrund dieser Werte werde ich mich weiter dem RandomForest widmen, da dies die zuverlässigsten Ergebnisse liefert (hohe Precision) und hohe Gesamtgenauigkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung von SMOTE, um den Bias weiter zu reduzieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf_smote = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"smote\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_rf_smote.fit(features_train, target_train)\n",
    "\n",
    "target_pred_rf_smote = pipeline_rf_smote.predict(features_test)\n",
    "\n",
    "print(\"Classification Report Random Forest with SMOTE:\\n\", classification_report(target_test, target_pred_rf_smote))\n",
    "print(\"RandomForest mit SMOTE:\\n\", accuracy_score(target_test, target_pred_rf_smote), precision_score(target_test, target_pred_rf_smote), recall_score(target_test, target_pred_rf_smote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bewertung SMOTE\n",
    "|Modell | Accuracy | Precision | Recall|\n",
    "|:------|:---------|:----------|:------|\n",
    "|RandomForest|0.856|0.748|0.607|\n",
    "|RandomForest SMOTE|0.845|0.675|0.688|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equalized Odds Difference (EOD) für 'sex': 0.0961\n",
      "\n",
      "Equalized Odds Difference (EOD) für 'race': 0.2333\n"
     ]
    }
   ],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für RandomForest\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für RandomForest mit SMOTE\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_smote,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_smote,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für DecisionTree\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_dt,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_dt,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für Logistische Regression\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_log_base,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_log_base,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Demographic Parity Difference für 'sex': 0.1819\n",
      "Demographic Parity Difference für 'race': 0.2399\n"
     ]
    }
   ],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für RandomForest\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für RandomForest mit SMOTE\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_smote, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_smote, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für DecisionTree\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_dt, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_dt, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für LogistischeRegression\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_log_base, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_log_base, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 16:00:46,674] A new study created in memory with name: no-name-3c463f11-5e50-4cb3-90dc-79df6787e2e4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 16:01:00,267] Trial 0 finished with value: 0.8224170245296806 and parameters: {'n_estimators': 125, 'max_depth': 15, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8224170245296806.\n",
      "[I 2025-02-25 16:01:07,377] Trial 1 finished with value: 0.8266764255885822 and parameters: {'n_estimators': 61, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8266764255885822.\n",
      "[I 2025-02-25 16:01:13,141] Trial 2 finished with value: 0.7897978025689869 and parameters: {'n_estimators': 217, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8266764255885822.\n",
      "[I 2025-02-25 16:01:16,539] Trial 3 finished with value: 0.7945264857244858 and parameters: {'n_estimators': 136, 'max_depth': 6, 'max_features': 'log2', 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8266764255885822.\n",
      "[I 2025-02-25 16:01:33,312] Trial 4 finished with value: 0.8271325340243959 and parameters: {'n_estimators': 141, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.8271325340243959.\n",
      "[I 2025-02-25 16:01:38,178] Trial 5 finished with value: 0.7909681042447039 and parameters: {'n_estimators': 172, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8271325340243959.\n",
      "[I 2025-02-25 16:01:40,191] Trial 6 finished with value: 0.7851297515135949 and parameters: {'n_estimators': 111, 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8271325340243959.\n",
      "[I 2025-02-25 16:01:47,390] Trial 7 finished with value: 0.8271600072464865 and parameters: {'n_estimators': 56, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.8271600072464865.\n",
      "[I 2025-02-25 16:01:50,686] Trial 8 finished with value: 0.7861770329365124 and parameters: {'n_estimators': 159, 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.8271600072464865.\n",
      "[I 2025-02-25 16:02:12,523] Trial 9 finished with value: 0.8273913439067716 and parameters: {'n_estimators': 170, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8273913439067716.\n",
      "[I 2025-02-25 16:02:30,629] Trial 10 finished with value: 0.8226160970774647 and parameters: {'n_estimators': 241, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8273913439067716.\n",
      "[I 2025-02-25 16:02:35,943] Trial 11 finished with value: 0.8227695656265044 and parameters: {'n_estimators': 57, 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8273913439067716.\n",
      "[I 2025-02-25 16:02:55,415] Trial 12 finished with value: 0.8249320809594319 and parameters: {'n_estimators': 194, 'max_depth': 12, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8273913439067716.\n",
      "[I 2025-02-25 16:03:00,346] Trial 13 finished with value: 0.8135299916525401 and parameters: {'n_estimators': 90, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8273913439067716.\n",
      "[I 2025-02-25 16:03:24,927] Trial 14 finished with value: 0.8283131709523307 and parameters: {'n_estimators': 181, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8283131709523307.\n",
      "[I 2025-02-25 16:03:55,015] Trial 15 finished with value: 0.8255080356294879 and parameters: {'n_estimators': 184, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.8283131709523307.\n",
      "[I 2025-02-25 16:04:06,192] Trial 16 finished with value: 0.8132593827124278 and parameters: {'n_estimators': 207, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.8283131709523307.\n",
      "[I 2025-02-25 16:04:31,013] Trial 17 finished with value: 0.8245631763108631 and parameters: {'n_estimators': 250, 'max_depth': 12, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8283131709523307.\n",
      "[I 2025-02-25 16:04:42,254] Trial 18 finished with value: 0.81981463452661 and parameters: {'n_estimators': 159, 'max_depth': 13, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8283131709523307.\n",
      "[I 2025-02-25 16:05:00,444] Trial 19 finished with value: 0.8220310849552838 and parameters: {'n_estimators': 223, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.8283131709523307.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beste Hyperparameter für Random Forest:\n",
      "{'n_estimators': 181, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 3}\n",
      "\n",
      "Optimierungsergebnisse:\n",
      "   Number of iterations  Iteration Number of Optimal Hyperparameters  \\\n",
      "0                    20                                           14   \n",
      "\n",
      "      Score  Time Elapsed (s)  \n",
      "0  0.828313        253.768299  \n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optimization of the RandomForest Hyperparameter\"\"\"\n",
    "\n",
    "    #Searchspace\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 250)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\"])\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10, step=2)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 4)\n",
    "\n",
    "    #Model\n",
    "    params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_features\": max_features,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf\n",
    "    }\n",
    "\n",
    "    model_rf = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **params)\n",
    "\n",
    "    num_cols = features_train.select_dtypes(include=[\"int64\"]).columns\n",
    "    cat_cols = features_train.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model_rf)\n",
    "    ])\n",
    "\n",
    "    score = cross_val_score(\n",
    "        estimator=pipeline, \n",
    "        X=features_train, \n",
    "        y=target_train, \n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=3,\n",
    "        n_jobs=1\n",
    "    ).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# create a study and setting a seed for reproduceability\n",
    "study = optuna.create_study(sampler=TPESampler(seed=42), direction='maximize')\n",
    "\n",
    "# perform hyperparameter tuning\n",
    "time_start = time.time()\n",
    "\n",
    "# starting optimization process with our defined function \n",
    "study.optimize(objective, n_trials=20)\n",
    "time_bayesian = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_bayesian = [\n",
    "    20, \n",
    "    study.best_trial.number, \n",
    "    study.best_trial.value, \n",
    "    time_bayesian\n",
    "]\n",
    "\n",
    "results_bayesian = pd.DataFrame([values_bayesian], columns=[\n",
    "    \"Number of iterations\", \n",
    "    \"Iteration Number of Optimal Hyperparameters\", \n",
    "    \"Score\", \n",
    "    \"Time Elapsed (s)\"\n",
    "])\n",
    "\n",
    "# best hyperparameter\n",
    "print(\"\\nBeste Hyperparameter für Random Forest:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "# show results\n",
    "print(\"\\nOptimierungsergebnisse:\")\n",
    "print(results_bayesian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Hyperparameter\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "model_rf_ba = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **best_params)\n",
    "pipeline_rf_ba = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", model_rf_ba)\n",
    "])\n",
    "\n",
    "pipeline_rf_ba.fit(features_train, target_train)\n",
    "target_pred_rf_ba = pipeline_rf_ba.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equalized Odds Difference (EOD) für 'sex': 0.2656\n",
      "\n",
      "Equalized Odds Difference (EOD) für 'race': 0.2278\n",
      "\n",
      "Demographic Parity Difference für 'sex': 0.3739\n",
      "Demographic Parity Difference für 'race': 0.2810\n"
     ]
    }
   ],
   "source": [
    "# Fairness-Metriken\n",
    "# Fairness-Metriken Equalized Odds Difference für Logistische Regression\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_ba,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_ba,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")\n",
    "\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_ba, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_ba, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ohne die Spalte fnlwgt für RandomForest\n",
    "# Features:\n",
    "features_train_mod = features_train.drop(\"fnlwgt\", axis=1)\n",
    "features_test_mod = features_test.drop(\"fnlwgt\", axis=1)\n",
    "\n",
    "# preprocessor\n",
    "num_cols_mod = features_train_mod.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols_mod = features_train_mod.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "preprocessor_mod = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols_mod),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols_mod)\n",
    "])\n",
    "# Modell\n",
    "pipeline_rf_mod = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_mod),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_rf_mod.fit(features_train_mod, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_rf_mod = pipeline_rf_mod.predict(features_test_mod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 16:07:39,839] A new study created in memory with name: no-name-4d5174d1-7c93-476b-a05c-e4ad20f765c8\n",
      "[I 2025-02-25 16:07:52,712] Trial 0 finished with value: 0.8212282193840106 and parameters: {'n_estimators': 125, 'max_depth': 15, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8212282193840106.\n",
      "[I 2025-02-25 16:07:59,193] Trial 1 finished with value: 0.8272768126659867 and parameters: {'n_estimators': 61, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8272768126659867.\n",
      "[I 2025-02-25 16:08:04,572] Trial 2 finished with value: 0.7894411635409849 and parameters: {'n_estimators': 217, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8272768126659867.\n",
      "[I 2025-02-25 16:08:07,954] Trial 3 finished with value: 0.7930952109679249 and parameters: {'n_estimators': 136, 'max_depth': 6, 'max_features': 'log2', 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8272768126659867.\n",
      "[I 2025-02-25 16:08:23,262] Trial 4 finished with value: 0.8269923834737526 and parameters: {'n_estimators': 141, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8272768126659867.\n",
      "[I 2025-02-25 16:08:27,526] Trial 5 finished with value: 0.789289357103453 and parameters: {'n_estimators': 172, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8272768126659867.\n",
      "[I 2025-02-25 16:08:29,428] Trial 6 finished with value: 0.7840742198856997 and parameters: {'n_estimators': 111, 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8272768126659867.\n",
      "[I 2025-02-25 16:08:35,855] Trial 7 finished with value: 0.8264719855099022 and parameters: {'n_estimators': 56, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8272768126659867.\n",
      "[I 2025-02-25 16:08:39,121] Trial 8 finished with value: 0.7852587063064621 and parameters: {'n_estimators': 159, 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8272768126659867.\n",
      "[I 2025-02-25 16:08:59,491] Trial 9 finished with value: 0.8279252207174538 and parameters: {'n_estimators': 170, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8279252207174538.\n",
      "[I 2025-02-25 16:09:16,397] Trial 10 finished with value: 0.821788115424197 and parameters: {'n_estimators': 241, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8279252207174538.\n",
      "[I 2025-02-25 16:09:21,145] Trial 11 finished with value: 0.822943988280879 and parameters: {'n_estimators': 57, 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8279252207174538.\n",
      "[I 2025-02-25 16:09:38,502] Trial 12 finished with value: 0.8254119996582808 and parameters: {'n_estimators': 194, 'max_depth': 12, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.8279252207174538.\n",
      "[I 2025-02-25 16:09:43,098] Trial 13 finished with value: 0.8105157891424657 and parameters: {'n_estimators': 90, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8279252207174538.\n",
      "[I 2025-02-25 16:10:05,253] Trial 14 finished with value: 0.8285518869707564 and parameters: {'n_estimators': 181, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8285518869707564.\n",
      "[I 2025-02-25 16:10:28,240] Trial 15 finished with value: 0.8286315821421327 and parameters: {'n_estimators': 184, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 15 with value: 0.8286315821421327.\n",
      "[I 2025-02-25 16:10:38,154] Trial 16 finished with value: 0.813736386546594 and parameters: {'n_estimators': 198, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 15 with value: 0.8286315821421327.\n",
      "[I 2025-02-25 16:11:10,600] Trial 17 finished with value: 0.8283380309239458 and parameters: {'n_estimators': 250, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 15 with value: 0.8286315821421327.\n",
      "[I 2025-02-25 16:11:22,259] Trial 18 finished with value: 0.8192788922956519 and parameters: {'n_estimators': 195, 'max_depth': 12, 'max_features': 'log2', 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 15 with value: 0.8286315821421327.\n",
      "[I 2025-02-25 16:11:40,332] Trial 19 finished with value: 0.8221219667814691 and parameters: {'n_estimators': 221, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.8286315821421327.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beste Hyperparameter für Random Forest:\n",
      "{'n_estimators': 184, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
      "\n",
      "Optimierungsergebnisse:\n",
      "   Number of iterations  Iteration Number of Optimal Hyperparameters  \\\n",
      "0                    20                                           15   \n",
      "\n",
      "      Score  Time Elapsed (s)  \n",
      "0  0.828632        240.492858  \n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optimization of the RandomForest Hyperparameter\"\"\"\n",
    "\n",
    "    #Searchspace\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 250)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\"])\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10, step=2)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 4)\n",
    "\n",
    "    #Model\n",
    "    params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_features\": max_features,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf\n",
    "    }\n",
    "\n",
    "    model_rf_mod = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **params)\n",
    "\n",
    "    num_cols_mod = features_train_mod.select_dtypes(include=[\"int64\"]).columns\n",
    "    cat_cols_mod = features_train_mod.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "    preprocessor_mod = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_cols_mod),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_mod)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    pipeline_mod = Pipeline([\n",
    "        (\"preprocessor\", preprocessor_mod),\n",
    "        (\"model\", model_rf_mod)\n",
    "    ])\n",
    "\n",
    "    score = cross_val_score(\n",
    "        estimator=pipeline_mod, \n",
    "        X=features_train_mod, \n",
    "        y=target_train, \n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=3,\n",
    "        n_jobs=1\n",
    "    ).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# create a study and setting a seed for reproduceability\n",
    "study = optuna.create_study(sampler=TPESampler(seed=42), direction='maximize')\n",
    "\n",
    "# perform hyperparameter tuning\n",
    "time_start = time.time()\n",
    "\n",
    "# starting optimization process with our defined function \n",
    "study.optimize(objective, n_trials=20)\n",
    "time_bayesian = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_bayesian = [\n",
    "    20, \n",
    "    study.best_trial.number, \n",
    "    study.best_trial.value, \n",
    "    time_bayesian\n",
    "]\n",
    "\n",
    "results_bayesian = pd.DataFrame([values_bayesian], columns=[\n",
    "    \"Number of iterations\", \n",
    "    \"Iteration Number of Optimal Hyperparameters\", \n",
    "    \"Score\", \n",
    "    \"Time Elapsed (s)\"\n",
    "])\n",
    "\n",
    "# best hyperparameter\n",
    "print(\"\\nBeste Hyperparameter für Random Forest:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "# show results\n",
    "print(\"\\nOptimierungsergebnisse:\")\n",
    "print(results_bayesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_mod = study.best_params\n",
    "\n",
    "model_rf_ba_mod = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **best_params)\n",
    "pipeline_rf_ba_mod = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_mod),\n",
    "    (\"model\", model_rf_ba_mod)\n",
    "])\n",
    "\n",
    "pipeline_rf_ba_mod.fit(features_train_mod, target_train)\n",
    "target_pred_rf_ba_mod = pipeline_rf_ba_mod.predict(features_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>EOD 'sex'</th>\n",
       "      <th>EOD 'race'</th>\n",
       "      <th>DPD 'sex'</th>\n",
       "      <th>DPD 'race'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>56.930272</td>\n",
       "      <td>85.395408</td>\n",
       "      <td>68.316327</td>\n",
       "      <td>0.219264</td>\n",
       "      <td>0.459748</td>\n",
       "      <td>0.324230</td>\n",
       "      <td>0.238946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>61.499039</td>\n",
       "      <td>61.224490</td>\n",
       "      <td>61.361457</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.190461</td>\n",
       "      <td>0.137756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>73.498498</td>\n",
       "      <td>62.436224</td>\n",
       "      <td>67.517241</td>\n",
       "      <td>0.069254</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>0.137158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestBaysian</th>\n",
       "      <td>55.747588</td>\n",
       "      <td>88.456633</td>\n",
       "      <td>68.392505</td>\n",
       "      <td>0.260909</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.369118</td>\n",
       "      <td>0.218644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modifizierter RandomForest</th>\n",
       "      <td>69.429708</td>\n",
       "      <td>66.772959</td>\n",
       "      <td>68.075423</td>\n",
       "      <td>0.089175</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.198801</td>\n",
       "      <td>0.150648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modifizierter RandomForestBaysian</th>\n",
       "      <td>55.551134</td>\n",
       "      <td>89.030612</td>\n",
       "      <td>68.414604</td>\n",
       "      <td>0.263574</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.369172</td>\n",
       "      <td>0.225079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   precision     recall         f1  EOD 'sex'  \\\n",
       "LogisticRegression                 56.930272  85.395408  68.316327   0.219264   \n",
       "DecisionTree                       61.499039  61.224490  61.361457   0.100722   \n",
       "RandomForest                       73.498498  62.436224  67.517241   0.069254   \n",
       "RandomForestBaysian                55.747588  88.456633  68.392505   0.260909   \n",
       "Modifizierter RandomForest         69.429708  66.772959  68.075423   0.089175   \n",
       "Modifizierter RandomForestBaysian  55.551134  89.030612  68.414604   0.263574   \n",
       "\n",
       "                                   EOD 'race'  DPD 'sex'  DPD 'race'  \n",
       "LogisticRegression                   0.459748   0.324230    0.238946  \n",
       "DecisionTree                         0.259259   0.190461    0.137756  \n",
       "RandomForest                         0.433333   0.176435    0.137158  \n",
       "RandomForestBaysian                  0.185185   0.369118    0.218644  \n",
       "Modifizierter RandomForest           0.233333   0.198801    0.150648  \n",
       "Modifizierter RandomForestBaysian    0.185185   0.369172    0.225079  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_target_list = [target_pred_log_base, target_pred_dt, target_pred_rf, target_pred_rf_ba, target_pred_rf_mod, target_pred_rf_ba_mod]\n",
    "model_name = [\"LogisticRegression\", \"DecisionTree\", \"RandomForest\", \"RandomForestBaysian\", \"Modifizierter RandomForest\", \"Modifizierter RandomForestBaysian\"]\n",
    "mod_qual = []\n",
    "\n",
    "for target in pred_target_list:\n",
    "    precision = precision_score(target_test, target)\n",
    "    recall = recall_score(target_test, target)\n",
    "    f1 = f1_score(target_test, target)\n",
    "    eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "    eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "    \n",
    "    dp_diff_sex = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "    dp_diff_race = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"race\"])\n",
    "    \n",
    "    mod_qual.append({\n",
    "                    \"precision\": (precision*100), \"recall\": (recall*100), \"f1\":(f1*100), \n",
    "                    \"EOD 'sex'\": (eq_odds_diff_sex),\n",
    "                    \"EOD 'race'\": (eq_odds_diff_race),\n",
    "                    \"DPD 'sex'\": (dp_diff_sex),\n",
    "                    \"DPD 'race'\": (dp_diff_race)\n",
    "                    })\n",
    "    \n",
    "df_mod_qual = pd.DataFrame(mod_qual, index=model_name)\n",
    "df_mod_qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bewertung\n",
    "- RandomForest hat vorraussichtlich die besten Werte im Gegensatz zu Logistische Regression und DecisionTree\n",
    "- Baysian scheint keine Verbesserung der Bewertung zu bringen -> Overfitting?\n",
    "- Ohne die Spalte \"fnlwgt\" etwas fairer, vorallem  bei EOD \"race\" \n",
    "\n",
    "Weiteres Vorgehen:\n",
    "ROC-AUC, DI\n",
    "Feature-Importance (siehe oben)\n",
    "Fairness-Korrekturen:\n",
    "- Preprocessing-Techniken (Reweighing, Fair Representation Learning)\n",
    "- In-Processing-Techniken (Adversarial Debiasing, Fair Loss Functions)\n",
    "- Postprocessing-Techniken (Equalized Odds Postprocessing, Reject Option Classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
