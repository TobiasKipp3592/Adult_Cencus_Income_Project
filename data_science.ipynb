{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from data_cleaning import fill_missing_values, rename_columns\n",
    "from data_science_skript import preprocess_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Kimi\\Arbeit\\Weiterbildung DADS\\Stackfuel\\Portfolio\\PortfolioProject\\.data\\adult.csv\", na_values=[\"?\"]) \n",
    "df = fill_missing_values(df) \n",
    "df = rename_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diskriminierung beim Datensatz\n",
    "\n",
    "plt.style.use('dark_background')  \n",
    "colors = [\"silver\", \"teal\"]\n",
    "\n",
    "# Einkommensverteilung nach Geschlecht\n",
    "income_gender = df.groupby(['sex', 'income']).size().unstack()\n",
    "income_gender.plot(kind='bar', stacked=True, color = colors, figsize=(8, 5))\n",
    "plt.title(\"Einkommensverteilung nach Geschlecht\")\n",
    "plt.xlabel(\"Geschlecht\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Einkommen\")\n",
    "plt.show()\n",
    "\n",
    "# Einkommensverteilung nach Ethnie\n",
    "income_race = df.groupby(['race', 'income']).size().unstack()\n",
    "income_race.plot(kind='bar', stacked=True, color = colors, figsize=(10, 5))\n",
    "plt.title(\"Einkommensverteilung nach Ethnie\")\n",
    "plt.xlabel(\"Ethnie\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Einkommen\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic Parity für Geschlecht\n",
    "gender_parity = df[df['income'] == '>50K']['sex'].value_counts(normalize=True)\n",
    "print(gender_parity)\n",
    "\n",
    "# Demographic Parity für Ethnie\n",
    "race_parity = df[df['income'] == '>50K']['race'].value_counts(normalize=True)\n",
    "print(race_parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies deutet auf starke Unterschiede in der Einkommensverteilung hin und muss beim Feature-Engeneering mit beachtet werden\n",
    "- Geschlecht und Ethnie sollte als sensible Merkmale beachtet werden\n",
    "- verschiedene Korkkekturne: Reweightung, Fairness Constraints\n",
    "\n",
    "### Fairness in der Vorhersage messen:\n",
    "- Falsch Positive und Falsch Negativ messen\n",
    "- Disparate Impact Score = Rate der pos Ergebnisse für die benachteiligten Gruppe / Rate der pos Ergebnisse für die bevorzugte Gruppe (>0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellauswahl\n",
    "- Logistisches Modell \n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Neuronale Netze?\n",
    "### Fairness-optimierte Modelle\n",
    "- Fair Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variablen umwandeln\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[\"int64\"])\n",
    "sns.heatmap(df_numeric.corr(),cmap=\"plasma\", vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der Feature-Correlation\n",
    "- education_num\n",
    "- age\n",
    "- sex, hours_per_week, age, income scheinen eine gewisse Korrelation zu haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "target = df[\"income\"]\n",
    "features = df.drop(columns=[\"income\"])\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainingsdaten:\\n\",features_train.shape)\n",
    "print(\"\\nTestdaten:\\n\",features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.countplot(x=target_train, ax=ax[0])\n",
    "ax[0].set_title(\"Klassenverteilung im Training-Set\")\n",
    "\n",
    "sns.countplot(x=target_test, ax=ax[1])\n",
    "ax[1].set_title(\"Klassenverteilung im Test-Set\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crosstab_income = pd.crosstab(index=target_train, columns = \"count\", normalize = \"columns\")\n",
    "test_crosstab_income = pd.crosstab(index=target_test, columns = \"count\", normalize = \"columns\")\n",
    "display(train_crosstab_income)\n",
    "display(test_crosstab_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalssenverteilung\n",
    "Es ist ein deutliches Ungleichgewicht der Zielkategorie zu erkennen:\n",
    "- class_weight = balanced\n",
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorbereitung\n",
    "num_cols = features_train.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols = features_train.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols)\n",
    "])\n",
    "\n",
    "# Baselinemodell Logistische Regression\n",
    "\n",
    "pipeline_log_base = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(class_weight=\"balanced\", random_state = 42))\n",
    "     ])\n",
    "\n",
    "pipeline_log_base.fit(features_train,target_train)\n",
    "target_pred_log_base = pipeline_log_base.predict(features_test)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score(target_test, target_pred_log_base))\n",
    "print(\"Classification report\\n\", classification_report(target_test, target_pred_log_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erste Bewertung \n",
    "Das Modell zeigt eine klare Diskriminierung:\n",
    "\n",
    "### Precision\n",
    "    - Einkommen > 50K werden ungenauer (nur mit 57% Wahrscheinlichkeit richtig vorhergesagt)\n",
    "    --> Diskriminierung gegen zu hoch verdienende ?\n",
    "\n",
    "### Recall\n",
    "    - relativ gut und ausgeglichen\n",
    "\n",
    "### F1-Score\n",
    "    - auch hier werden Hochverdiener deutlich schlechter erkannt\n",
    "\n",
    "### Ursachen:\n",
    "- Datenungleichgewicht\n",
    "- Feature Bias\n",
    "- andere Modelle können eventuell besser unterscheiden (RandomForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Anpassung\n",
    "\n",
    "crit_cols = [\"sex\", \"race\"]\n",
    "features_train_crit = features_train.drop(columns=crit_cols)\n",
    "features_test_crit = features_test.drop(columns=crit_cols)\n",
    "\n",
    "num_cols_crit = features_train_crit.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols_crit = features_train_crit.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "preprocessor_crit = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols_crit),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols_crit)\n",
    "])\n",
    "\n",
    "pipeline_log_base_crit = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_crit),\n",
    "    (\"model\", LogisticRegression(class_weight=\"balanced\", random_state = 42))\n",
    "     ])\n",
    "\n",
    "pipeline_log_base_crit.fit(features_train_crit, target_train)\n",
    "target_pred_log_base_crit = pipeline_log_base_crit.predict(features_test_crit)\n",
    "\n",
    "print(\"LogistischeRegression\\n\", classification_report(target_test, target_pred_log_base_crit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Importance des Base-Line Modells\n",
    "feature_names = list(num_cols) + list(pipeline_log_base.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols))\n",
    "coefficients = pipeline_log_base.named_steps[\"model\"].coef_[0]\n",
    "feature_importance = pd.Series(data = pipeline_log_base.named_steps[\"model\"].coef_[0],\n",
    "                               index = feature_names).sort_values(ascending=False)\n",
    "# Feature Importance OHNE sex and race\n",
    "feature_names_crit = list(num_cols_crit) + list(pipeline_log_base_crit.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols_crit))\n",
    "coefficients_crit = pipeline_log_base_crit.named_steps[\"model\"].coef_[0]\n",
    "feature_importance_crit = pd.Series(data = pipeline_log_base_crit.named_steps[\"model\"].coef_[0],\n",
    "                               index = feature_names_crit).sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10)) \n",
    "feature_importance.head(20).plot(kind='barh', ax = ax[0])\n",
    "feature_importance_crit.head(20).plot(kind='barh', ax = ax[1])\n",
    "\n",
    "ax[0].set_title(\"Feature Importance mit allen Features\")\n",
    "ax[1].set_title(\"Feature Importance ohne 'sex' und 'race'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der Feature-Importance\n",
    "- Herkunftsländer scheinen eine auffällig große Rolle zu spielen\n",
    "- das Geschlecht und die Rasse dafür nicht direkt.\n",
    "- --> es gibt aber andere Metriken, die indirekt auf ein Geschlecht hinweisen(Education, Occupation, Relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_log_base[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_log_base[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_log_base[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für Ethnie\n",
    "\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_log_base[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_log_base[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_log_base[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazit zum ersten Baselinemodell Logistische Regression\n",
    "## Geschlecht\n",
    "\n",
    "#### Leichte Diskriminierung erkennbar:\n",
    "Recall (Female: 74,7%, Male: 86,7%)\n",
    "- Frauen, die tatsächlich Hochverdiener sind, werden schlechter erkannt (niedrigerer Recall)\n",
    "- Männer haben einen höheren Recall, das heißt Männer werden besser als Hochverdiener erkannt\n",
    "\n",
    "Accuracy (Female: 91,3%, Male: 75,6%):\n",
    "- Frauen werden besser klassifiziert als Männer:\n",
    "    - die meisten Frauen sind in der Kategorie <=50K\n",
    "    - weitere Features deuten auf Frauen hin (Relationship)\n",
    "\n",
    "Precision (Female: 59,8%, Male: 56,4%):\n",
    "- Ergebnisse sind sehr ähnlich\n",
    "\n",
    "## Ethnie\n",
    "- Das Modell erkennt Hochverdiener aus bestimmten ethnischen Gruppen schlechter:\n",
    "    - Recall für White besonders gut (85,8%) im Gegensatz zu indigenen und \"other\"\n",
    "    - Precision für Indigene besonders schlecht\n",
    "    -Precision für Other extrem gut - Datenset-Problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree\n",
    "# Modell\n",
    "pipeline_dt = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", DecisionTreeClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_dt.fit(features_train, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_dt = pipeline_dt.predict(features_test)\n",
    "\n",
    "#Kennzahlen\n",
    "print(\"DecisionTree:\\n\", classification_report(target_test, target_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "# Modell\n",
    "pipeline_rf = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_rf.fit(features_train, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_rf = pipeline_rf.predict(features_test)\n",
    "\n",
    "#Kennzahlen\n",
    "print(\"RandomForest:\\n\", classification_report(target_test, target_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_names = list(num_cols) + list(pipeline_rf.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols))\n",
    "\n",
    "# Für den DecisionTree\n",
    "feature_importance_dt = pd.Series(data=pipeline_dt.named_steps[\"model\"].feature_importances_,\n",
    "                               index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#RandomForest\n",
    "feature_importance_rf = pd.Series(data=pipeline_rf.named_steps[\"model\"].feature_importances_,\n",
    "                               index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10)) \n",
    "feature_importance_dt.head(20).plot(kind='barh', ax = ax[0])\n",
    "feature_importance_rf.head(20).plot(kind='barh', ax = ax[1])\n",
    "\n",
    "ax[0].set_title(\"Feature Importance Decision Tree\")\n",
    "ax[1].set_title(\"Feature Importance Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für DecisionTree\n",
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "print(\"DecisionTree\")\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_dt[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_dt[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_dt[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_dt[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_dt[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_dt[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für RandomForest\n",
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "print(\"RandomForest\")\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_rf[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_rf[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_rf[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_rf[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_rf[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_rf[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LogisticRegression:\\n\", accuracy_score(target_test, target_pred_log_base), precision_score(target_test, target_pred_log_base), recall_score(target_test, target_pred_log_base))\n",
    "print(\"DecisionTree:\\n\", accuracy_score(target_test, target_pred_dt), precision_score(target_test, target_pred_dt), recall_score(target_test, target_pred_dt))\n",
    "print(\"RandomForest:\\n\", accuracy_score(target_test, target_pred_rf), precision_score(target_test, target_pred_rf), recall_score(target_test, target_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der einzelnen Basismodelle\n",
    "|Modell | Accuracy | Precision | Recall|\n",
    "|:------|:---------|:----------|:------|\n",
    "|Logistische Regression|0.808|0.568|0.848|\n",
    "|DecisionTree|0.815|0.619|0.605|\n",
    "|RandomForest|0.856|0.748|0.607|\n",
    "\n",
    "Aufgrund dieser Werte werde ich mich weiter dem RandomForest widmen, da dies die zuverlässigsten Ergebnisse liefert (hohe Precision) und hohe Gesamtgenauigkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung von SMOTE, um den Bias weiter zu reduzieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf_smote = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"smote\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_rf_smote.fit(features_train, target_train)\n",
    "\n",
    "target_pred_rf_smote = pipeline_rf_smote.predict(features_test)\n",
    "\n",
    "print(\"Classification Report Random Forest with SMOTE:\\n\", classification_report(target_test, target_pred_rf_smote))\n",
    "print(\"RandomForest mit SMOTE:\\n\", accuracy_score(target_test, target_pred_rf_smote), precision_score(target_test, target_pred_rf_smote), recall_score(target_test, target_pred_rf_smote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bewertung SMOTE\n",
    "|Modell | Accuracy | Precision | Recall|\n",
    "|:------|:---------|:----------|:------|\n",
    "|RandomForest|0.856|0.748|0.607|\n",
    "|RandomForest SMOTE|0.845|0.675|0.688|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
