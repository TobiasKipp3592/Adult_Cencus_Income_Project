{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from data_cleaning import fill_missing_values, rename_columns\n",
    "from data_science_skript import preprocess_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import optuna\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "\n",
    "from fairlearn.metrics import equalized_odds_difference\n",
    "from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\kimko\\PortfolioProjekt\\adult.csv\", na_values=[\"?\"]) \n",
    "df = fill_missing_values(df) \n",
    "df = rename_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diskriminierung beim Datensatz\n",
    "\n",
    "plt.style.use(\"dark_background\")  \n",
    "colors = [\"silver\", \"teal\"]\n",
    "\n",
    "# Einkommensverteilung nach Geschlecht\n",
    "income_gender = df.groupby([\"sex\", \"income\"]).size().unstack()\n",
    "income_gender.plot(kind=\"bar\", stacked=True, color = colors, figsize=(8, 5))\n",
    "plt.title(\"Einkommensverteilung nach Geschlecht\")\n",
    "plt.xlabel(\"Geschlecht\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Einkommen\")\n",
    "plt.show()\n",
    "\n",
    "# Einkommensverteilung nach Ethnie\n",
    "income_race = df.groupby([\"race\",\"income\"]).size().unstack()\n",
    "income_race.plot(kind=\"bar\", stacked=True, color = colors, figsize=(10, 5))\n",
    "plt.title(\"Einkommensverteilung nach Ethnie\")\n",
    "plt.xlabel(\"Ethnie\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Einkommen\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic Parity für Geschlecht\n",
    "gender_parity = df[df[\"income\"] == '>50K']['sex'].value_counts(normalize=True)\n",
    "print(gender_parity)\n",
    "\n",
    "# Demographic Parity für Ethnie\n",
    "race_parity = df[df[\"income\"] == '>50K']['race'].value_counts(normalize=True)\n",
    "print(race_parity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies deutet auf starke Unterschiede in der Einkommensverteilung hin und muss beim Feature-Engeneering mit beachtet werden\n",
    "- Geschlecht und Ethnie sollte als sensible Merkmale beachtet werden\n",
    "- verschiedene Korkkekturne: Reweightung, Fairness Constraints\n",
    "\n",
    "### Fairness in der Vorhersage messen:\n",
    "- Falsch Positive und Falsch Negativ messen\n",
    "- Disparate Impact Score = Rate der pos Ergebnisse für die benachteiligten Gruppe / Rate der pos Ergebnisse für die bevorzugte Gruppe (>0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modellauswahl\n",
    "- Logistisches Modell \n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Neuronale Netze?\n",
    "### Fairness-optimierte Modelle\n",
    "- Fair Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variablen umwandeln\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.select_dtypes(include=[\"int64\"])\n",
    "sns.heatmap(df_numeric.corr(),cmap=\"plasma\", vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der Feature-Correlation\n",
    "- education_num\n",
    "- age\n",
    "- sex, hours_per_week, age, income scheinen eine gewisse Korrelation zu haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "target = df[\"income\"]\n",
    "features = df.drop(columns=[\"income\"])\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainingsdaten:\\n\",features_train.shape)\n",
    "print(\"\\nTestdaten:\\n\",features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.countplot(x=target_train, ax=ax[0])\n",
    "ax[0].set_title(\"Klassenverteilung im Training-Set\")\n",
    "\n",
    "sns.countplot(x=target_test, ax=ax[1])\n",
    "ax[1].set_title(\"Klassenverteilung im Test-Set\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crosstab_income = pd.crosstab(index=target_train, columns = \"count\", normalize = \"columns\")\n",
    "test_crosstab_income = pd.crosstab(index=target_test, columns = \"count\", normalize = \"columns\")\n",
    "display(train_crosstab_income)\n",
    "display(test_crosstab_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalssenverteilung\n",
    "Es ist ein deutliches Ungleichgewicht der Zielkategorie zu erkennen:\n",
    "- class_weight = balanced\n",
    "- SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8125287885766928\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.87      4945\n",
      "           1       0.57      0.85      0.69      1568\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.76      0.83      0.78      6513\n",
      "weighted avg       0.85      0.81      0.82      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vorbereitung\n",
    "num_cols = features_train.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols = features_train.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols)\n",
    "])\n",
    "\n",
    "# Baselinemodell Logistische Regression\n",
    "\n",
    "pipeline_log_base = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(class_weight=\"balanced\", random_state = 42))\n",
    "     ])\n",
    "\n",
    "pipeline_log_base.fit(features_train,target_train)\n",
    "target_pred_log_base = pipeline_log_base.predict(features_test)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score(target_test, target_pred_log_base))\n",
    "print(\"Classification report\\n\", classification_report(target_test, target_pred_log_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erste Bewertung \n",
    "Das Modell zeigt eine klare Diskriminierung:\n",
    "\n",
    "### Precision\n",
    "    - Einkommen > 50K werden ungenauer (nur mit 57% Wahrscheinlichkeit richtig vorhergesagt)\n",
    "    --> Diskriminierung gegen zu hoch verdienende ?\n",
    "\n",
    "### Recall\n",
    "    - relativ gut und ausgeglichen\n",
    "\n",
    "### F1-Score\n",
    "    - auch hier werden Hochverdiener deutlich schlechter erkannt\n",
    "\n",
    "### Ursachen:\n",
    "- Datenungleichgewicht\n",
    "- Feature Bias\n",
    "- andere Modelle können eventuell besser unterscheiden (RandomForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Anpassung\n",
    "\n",
    "crit_cols = [\"sex\", \"race\"]\n",
    "features_train_crit = features_train.drop(columns=crit_cols)\n",
    "features_test_crit = features_test.drop(columns=crit_cols)\n",
    "\n",
    "num_cols_crit = features_train_crit.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols_crit = features_train_crit.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "preprocessor_crit = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols_crit),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols_crit)\n",
    "])\n",
    "\n",
    "pipeline_log_base_crit = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_crit),\n",
    "    (\"model\", LogisticRegression(class_weight=\"balanced\", random_state = 42))\n",
    "     ])\n",
    "\n",
    "pipeline_log_base_crit.fit(features_train_crit, target_train)\n",
    "target_pred_log_base_crit = pipeline_log_base_crit.predict(features_test_crit)\n",
    "\n",
    "print(\"LogistischeRegression\\n\", classification_report(target_test, target_pred_log_base_crit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Importance des Base-Line Modells\n",
    "feature_names = list(num_cols) + list(pipeline_log_base.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols))\n",
    "coefficients = pipeline_log_base.named_steps[\"model\"].coef_[0]\n",
    "feature_importance = pd.Series(data = pipeline_log_base.named_steps[\"model\"].coef_[0],\n",
    "                               index = feature_names).sort_values(ascending=False)\n",
    "# Feature Importance OHNE sex and race\n",
    "feature_names_crit = list(num_cols_crit) + list(pipeline_log_base_crit.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols_crit))\n",
    "coefficients_crit = pipeline_log_base_crit.named_steps[\"model\"].coef_[0]\n",
    "feature_importance_crit = pd.Series(data = pipeline_log_base_crit.named_steps[\"model\"].coef_[0],\n",
    "                               index = feature_names_crit).sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10)) \n",
    "feature_importance.head(20).plot(kind='barh', ax = ax[0])\n",
    "feature_importance_crit.head(20).plot(kind='barh', ax = ax[1])\n",
    "\n",
    "ax[0].set_title(\"Feature Importance mit allen Features\")\n",
    "ax[1].set_title(\"Feature Importance ohne 'sex' und 'race'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der Feature-Importance\n",
    "- Herkunftsländer scheinen eine auffällig große Rolle zu spielen\n",
    "- das Geschlecht und die Rasse dafür nicht direkt.\n",
    "- --> es gibt aber andere Metriken, die indirekt auf ein Geschlecht hinweisen(Education, Occupation, Relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_log_base[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_log_base[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_log_base[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für Ethnie\n",
    "\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_log_base[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_log_base[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_log_base[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazit zum ersten Baselinemodell Logistische Regression\n",
    "## Geschlecht\n",
    "\n",
    "#### Leichte Diskriminierung erkennbar:\n",
    "Recall (Female: 74,7%, Male: 86,7%)\n",
    "- Frauen, die tatsächlich Hochverdiener sind, werden schlechter erkannt (niedrigerer Recall)\n",
    "- Männer haben einen höheren Recall, das heißt Männer werden besser als Hochverdiener erkannt\n",
    "\n",
    "Accuracy (Female: 91,3%, Male: 75,6%):\n",
    "- Frauen werden besser klassifiziert als Männer:\n",
    "    - die meisten Frauen sind in der Kategorie <=50K\n",
    "    - weitere Features deuten auf Frauen hin (Relationship)\n",
    "\n",
    "Precision (Female: 59,8%, Male: 56,4%):\n",
    "- Ergebnisse sind sehr ähnlich\n",
    "\n",
    "## Ethnie\n",
    "- Das Modell erkennt Hochverdiener aus bestimmten ethnischen Gruppen schlechter:\n",
    "    - Recall für White besonders gut (85,8%) im Gegensatz zu indigenen und \"other\"\n",
    "    - Precision für Indigene besonders schlecht\n",
    "    -Precision für Other extrem gut - Datenset-Problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      4945\n",
      "           1       0.62      0.61      0.62      1568\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.75      0.75      0.75      6513\n",
      "weighted avg       0.82      0.82      0.82      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree\n",
    "# Modell\n",
    "pipeline_dt = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", DecisionTreeClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_dt.fit(features_train, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_dt = pipeline_dt.predict(features_test)\n",
    "\n",
    "#Kennzahlen\n",
    "print(\"DecisionTree:\\n\", classification_report(target_test, target_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      4945\n",
      "           1       0.73      0.62      0.67      1568\n",
      "\n",
      "    accuracy                           0.85      6513\n",
      "   macro avg       0.81      0.77      0.79      6513\n",
      "weighted avg       0.85      0.85      0.85      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "# Modell\n",
    "pipeline_rf = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_rf.fit(features_train, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_rf = pipeline_rf.predict(features_test)\n",
    "\n",
    "#Kennzahlen\n",
    "print(\"RandomForest:\\n\", classification_report(target_test, target_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "feature_names = list(num_cols) + list(pipeline_rf.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(cat_cols))\n",
    "\n",
    "# Für den DecisionTree\n",
    "feature_importance_dt = pd.Series(data=pipeline_dt.named_steps[\"model\"].feature_importances_,\n",
    "                               index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#RandomForest\n",
    "feature_importance_rf = pd.Series(data=pipeline_rf.named_steps[\"model\"].feature_importances_,\n",
    "                               index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10)) \n",
    "feature_importance_dt.head(20).plot(kind='barh', ax = ax[0])\n",
    "feature_importance_rf.head(20).plot(kind='barh', ax = ax[1])\n",
    "\n",
    "ax[0].set_title(\"Feature Importance Decision Tree\")\n",
    "ax[1].set_title(\"Feature Importance Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für DecisionTree\n",
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "print(\"DecisionTree\")\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_dt[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_dt[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_dt[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_dt[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_dt[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_dt[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken für RandomForest\n",
    "# Fairness-Metriken berechnen für Geschlecht: 0 - Female / 1- Male\n",
    "print(\"RandomForest\")\n",
    "for group in features_test[\"sex\"].unique():\n",
    "    mask = (features_test[\"sex\"] == group)\n",
    "    acc = accuracy_score(target_test[mask], target_pred_rf[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_rf[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_rf[mask])\n",
    "\n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "for group in features_test[\"race\"].unique():  \n",
    "    mask = (features_test[\"race\"] == group)  \n",
    "    \n",
    "    acc = accuracy_score(target_test[mask], target_pred_rf[mask])\n",
    "    prec = precision_score(target_test[mask], target_pred_rf[mask])\n",
    "    rec = recall_score(target_test[mask], target_pred_rf[mask])\n",
    "    \n",
    "    print(f\"{group} - Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LogisticRegression:\\n\", accuracy_score(target_test, target_pred_log_base), precision_score(target_test, target_pred_log_base), recall_score(target_test, target_pred_log_base))\n",
    "print(\"DecisionTree:\\n\", accuracy_score(target_test, target_pred_dt), precision_score(target_test, target_pred_dt), recall_score(target_test, target_pred_dt))\n",
    "print(\"RandomForest:\\n\", accuracy_score(target_test, target_pred_rf), precision_score(target_test, target_pred_rf), recall_score(target_test, target_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung der einzelnen Basismodelle\n",
    "|Modell | Accuracy | Precision | Recall|\n",
    "|:------|:---------|:----------|:------|\n",
    "|Logistische Regression|0.808|0.568|0.848|\n",
    "|DecisionTree|0.815|0.619|0.605|\n",
    "|RandomForest|0.856|0.748|0.607|\n",
    "\n",
    "Aufgrund dieser Werte werde ich mich weiter dem RandomForest widmen, da dies die zuverlässigsten Ergebnisse liefert (hohe Precision) und hohe Gesamtgenauigkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung von SMOTE, um den Bias weiter zu reduzieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf_smote = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"smote\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_rf_smote.fit(features_train, target_train)\n",
    "\n",
    "target_pred_rf_smote = pipeline_rf_smote.predict(features_test)\n",
    "\n",
    "print(\"Classification Report Random Forest with SMOTE:\\n\", classification_report(target_test, target_pred_rf_smote))\n",
    "print(\"RandomForest mit SMOTE:\\n\", accuracy_score(target_test, target_pred_rf_smote), precision_score(target_test, target_pred_rf_smote), recall_score(target_test, target_pred_rf_smote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bewertung SMOTE\n",
    "|Modell | Accuracy | Precision | Recall|\n",
    "|:------|:---------|:----------|:------|\n",
    "|RandomForest|0.856|0.748|0.607|\n",
    "|RandomForest SMOTE|0.845|0.675|0.688|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equalized Odds Difference (EOD) für 'sex': 0.0961\n",
      "\n",
      "Equalized Odds Difference (EOD) für 'race': 0.2333\n"
     ]
    }
   ],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für RandomForest\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für RandomForest mit SMOTE\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_smote,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_smote,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für DecisionTree\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_dt,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_dt,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness-Metriken Equalized Odds Difference für Logistische Regression\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_log_base,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_log_base,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Demographic Parity Difference für 'sex': 0.1819\n",
      "Demographic Parity Difference für 'race': 0.2399\n"
     ]
    }
   ],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für RandomForest\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für RandomForest mit SMOTE\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_smote, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_smote, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für DecisionTree\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_dt, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_dt, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairness-Metriken Demographic Parity Difference für LogistischeRegression\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_log_base, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_log_base, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 19:38:53,952] A new study created in memory with name: no-name-17af59af-010e-423c-8691-8d18e865e114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 19:39:13,239] Trial 0 finished with value: 0.8218826669788749 and parameters: {'n_estimators': 125, 'max_depth': 15, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8218826669788749.\n",
      "[I 2025-02-25 19:39:24,759] Trial 1 finished with value: 0.8264415897510999 and parameters: {'n_estimators': 61, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8264415897510999.\n",
      "[I 2025-02-25 19:39:33,437] Trial 2 finished with value: 0.7882333231502855 and parameters: {'n_estimators': 217, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8264415897510999.\n",
      "[I 2025-02-25 19:39:37,752] Trial 3 finished with value: 0.7895501781746551 and parameters: {'n_estimators': 136, 'max_depth': 6, 'max_features': 'log2', 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8264415897510999.\n",
      "[I 2025-02-25 19:39:57,915] Trial 4 finished with value: 0.8265514634593903 and parameters: {'n_estimators': 141, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.8265514634593903.\n",
      "[I 2025-02-25 19:40:03,510] Trial 5 finished with value: 0.7876925680684232 and parameters: {'n_estimators': 172, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.8265514634593903.\n",
      "[I 2025-02-25 19:40:05,809] Trial 6 finished with value: 0.7828417420122259 and parameters: {'n_estimators': 111, 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8265514634593903.\n",
      "[I 2025-02-25 19:40:14,923] Trial 7 finished with value: 0.8272533220304661 and parameters: {'n_estimators': 56, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.8272533220304661.\n",
      "[I 2025-02-25 19:40:18,888] Trial 8 finished with value: 0.7845254789882942 and parameters: {'n_estimators': 159, 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.8272533220304661.\n",
      "[I 2025-02-25 19:40:46,324] Trial 9 finished with value: 0.8272405833418052 and parameters: {'n_estimators': 170, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.8272533220304661.\n",
      "[I 2025-02-25 19:40:51,722] Trial 10 finished with value: 0.8218722137127995 and parameters: {'n_estimators': 54, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.8272533220304661.\n",
      "[I 2025-02-25 19:41:14,702] Trial 11 finished with value: 0.8246326282943693 and parameters: {'n_estimators': 205, 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.8272533220304661.\n",
      "[I 2025-02-25 19:41:44,425] Trial 12 finished with value: 0.825525600106935 and parameters: {'n_estimators': 245, 'max_depth': 12, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.8272533220304661.\n",
      "[I 2025-02-25 19:41:50,173] Trial 13 finished with value: 0.8164436867468927 and parameters: {'n_estimators': 90, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.8272533220304661.\n",
      "[I 2025-02-25 19:42:18,730] Trial 14 finished with value: 0.8289534222941061 and parameters: {'n_estimators': 181, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8289534222941061.\n",
      "[I 2025-02-25 19:42:49,920] Trial 15 finished with value: 0.8280376462999879 and parameters: {'n_estimators': 194, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8289534222941061.\n",
      "[I 2025-02-25 19:43:05,031] Trial 16 finished with value: 0.8141563421143426 and parameters: {'n_estimators': 196, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8289534222941061.\n",
      "[I 2025-02-25 19:43:57,113] Trial 17 finished with value: 0.8278310622029122 and parameters: {'n_estimators': 247, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8289534222941061.\n",
      "[I 2025-02-25 19:44:11,642] Trial 18 finished with value: 0.8187243679966211 and parameters: {'n_estimators': 184, 'max_depth': 12, 'max_features': 'log2', 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8289534222941061.\n",
      "[I 2025-02-25 19:44:30,735] Trial 19 finished with value: 0.8214099813412697 and parameters: {'n_estimators': 222, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8289534222941061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beste Hyperparameter für Random Forest:\n",
      "{'n_estimators': 181, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
      "\n",
      "Optimierungsergebnisse:\n",
      "   Number of iterations  Iteration Number of Optimal Hyperparameters  \\\n",
      "0                    20                                           14   \n",
      "\n",
      "      Score  Time Elapsed (s)  \n",
      "0  0.828953        336.781859  \n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optimization of the RandomForest Hyperparameter\"\"\"\n",
    "\n",
    "    #Searchspace\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 250)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\"])\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10, step=2)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 4)\n",
    "\n",
    "    #Model\n",
    "    params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_features\": max_features,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf\n",
    "    }\n",
    "\n",
    "    model_rf = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **params)\n",
    "\n",
    "    num_cols = features_train.select_dtypes(include=[\"int64\"]).columns\n",
    "    cat_cols = features_train.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model_rf)\n",
    "    ])\n",
    "\n",
    "    score = cross_val_score(\n",
    "        estimator=pipeline, \n",
    "        X=features_train, \n",
    "        y=target_train, \n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=3,\n",
    "        n_jobs=1\n",
    "    ).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# create a study and setting a seed for reproduceability\n",
    "study = optuna.create_study(sampler=TPESampler(seed=42), direction='maximize')\n",
    "\n",
    "# perform hyperparameter tuning\n",
    "time_start = time.time()\n",
    "\n",
    "# starting optimization process with our defined function \n",
    "study.optimize(objective, n_trials=20)\n",
    "time_bayesian = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_bayesian = [\n",
    "    20, \n",
    "    study.best_trial.number, \n",
    "    study.best_trial.value, \n",
    "    time_bayesian\n",
    "]\n",
    "\n",
    "results_bayesian = pd.DataFrame([values_bayesian], columns=[\n",
    "    \"Number of iterations\", \n",
    "    \"Iteration Number of Optimal Hyperparameters\", \n",
    "    \"Score\", \n",
    "    \"Time Elapsed (s)\"\n",
    "])\n",
    "\n",
    "# best hyperparameter\n",
    "print(\"\\nBeste Hyperparameter für Random Forest:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "# show results\n",
    "print(\"\\nOptimierungsergebnisse:\")\n",
    "print(results_bayesian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung der Hyperparameter\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "model_rf_ba = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **best_params)\n",
    "pipeline_rf_ba = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", model_rf_ba)\n",
    "])\n",
    "\n",
    "pipeline_rf_ba.fit(features_train, target_train)\n",
    "target_pred_rf_ba = pipeline_rf_ba.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equalized Odds Difference (EOD) für 'sex': 0.2656\n",
      "\n",
      "Equalized Odds Difference (EOD) für 'race': 0.2278\n",
      "\n",
      "Demographic Parity Difference für 'sex': 0.3739\n",
      "Demographic Parity Difference für 'race': 0.2810\n"
     ]
    }
   ],
   "source": [
    "# Fairness-Metriken\n",
    "# Fairness-Metriken Equalized Odds Difference für Logistische Regression\n",
    "eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_ba,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target_pred_rf_ba,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'sex': {eq_odds_diff_sex:.4f}\")\n",
    "print(f\"\\nEqualized Odds Difference (EOD) für 'race': {eq_odds_diff_race:.4f}\")\n",
    "\n",
    "dp_diff_sex = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_ba, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "dp_diff_race = demographic_parity_difference(\n",
    "    y_pred=target_pred_rf_ba, \n",
    "    y_true=target_test,\n",
    "    sensitive_features=features_test[\"race\"])\n",
    "\n",
    "print(f\"\\nDemographic Parity Difference für 'sex': {dp_diff_sex:.4f}\")\n",
    "print(f\"Demographic Parity Difference für 'race': {dp_diff_race:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ohne die Spalte fnlwgt für RandomForest\n",
    "# Features:\n",
    "features_train_mod = features_train.drop(\"fnlwgt\", axis=1)\n",
    "features_test_mod = features_test.drop(\"fnlwgt\", axis=1)\n",
    "\n",
    "# preprocessor\n",
    "num_cols_mod = features_train_mod.select_dtypes(include=[\"int64\"]).columns\n",
    "cat_cols_mod = features_train_mod.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "preprocessor_mod = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols_mod),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols_mod)\n",
    "])\n",
    "# Modell\n",
    "pipeline_rf_mod = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_mod),\n",
    "    (\"model\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "#Anpassen des Modells\n",
    "pipeline_rf_mod.fit(features_train_mod, target_train)\n",
    "\n",
    "#Vorhersage\n",
    "target_pred_rf_mod = pipeline_rf_mod.predict(features_test_mod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 19:47:18,252] A new study created in memory with name: no-name-80c48004-8e84-48e2-9ac2-b859c28ae298\n",
      "[I 2025-02-25 19:47:32,090] Trial 0 finished with value: 0.822608531449725 and parameters: {'n_estimators': 125, 'max_depth': 15, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.822608531449725.\n",
      "[I 2025-02-25 19:47:39,187] Trial 1 finished with value: 0.8273855752894653 and parameters: {'n_estimators': 61, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8273855752894653.\n",
      "[I 2025-02-25 19:47:44,752] Trial 2 finished with value: 0.7880970988127597 and parameters: {'n_estimators': 217, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8273855752894653.\n",
      "[I 2025-02-25 19:47:48,050] Trial 3 finished with value: 0.7915168664316926 and parameters: {'n_estimators': 136, 'max_depth': 6, 'max_features': 'log2', 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8273855752894653.\n",
      "[I 2025-02-25 19:48:04,612] Trial 4 finished with value: 0.826895015888177 and parameters: {'n_estimators': 141, 'max_depth': 13, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8273855752894653.\n",
      "[I 2025-02-25 19:48:09,077] Trial 5 finished with value: 0.7868246070703497 and parameters: {'n_estimators': 172, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8273855752894653.\n",
      "[I 2025-02-25 19:48:11,014] Trial 6 finished with value: 0.7819207471891853 and parameters: {'n_estimators': 111, 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8273855752894653.\n",
      "[I 2025-02-25 19:48:17,841] Trial 7 finished with value: 0.8273320442135522 and parameters: {'n_estimators': 56, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8273855752894653.\n",
      "[I 2025-02-25 19:48:20,973] Trial 8 finished with value: 0.7853160024828839 and parameters: {'n_estimators': 159, 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8273855752894653.\n",
      "[I 2025-02-25 19:48:42,266] Trial 9 finished with value: 0.8283846058416241 and parameters: {'n_estimators': 170, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8283846058416241.\n",
      "[I 2025-02-25 19:48:59,427] Trial 10 finished with value: 0.8222598467252382 and parameters: {'n_estimators': 241, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8283846058416241.\n",
      "[I 2025-02-25 19:49:04,843] Trial 11 finished with value: 0.8223727683919536 and parameters: {'n_estimators': 57, 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 9 with value: 0.8283846058416241.\n",
      "[I 2025-02-25 19:49:24,818] Trial 12 finished with value: 0.8261666069509394 and parameters: {'n_estimators': 194, 'max_depth': 12, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.8283846058416241.\n",
      "[I 2025-02-25 19:49:29,766] Trial 13 finished with value: 0.811835896408167 and parameters: {'n_estimators': 90, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.8283846058416241.\n",
      "[I 2025-02-25 19:49:54,658] Trial 14 finished with value: 0.8286956990495172 and parameters: {'n_estimators': 181, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8286956990495172.\n",
      "[I 2025-02-25 19:50:21,215] Trial 15 finished with value: 0.8283048608020595 and parameters: {'n_estimators': 184, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8286956990495172.\n",
      "[I 2025-02-25 19:50:33,311] Trial 16 finished with value: 0.8140024223465309 and parameters: {'n_estimators': 207, 'max_depth': 8, 'max_features': 'sqrt', 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.8286956990495172.\n",
      "[I 2025-02-25 19:51:03,118] Trial 17 finished with value: 0.8259361512145964 and parameters: {'n_estimators': 250, 'max_depth': 12, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.8286956990495172.\n",
      "[I 2025-02-25 19:51:15,282] Trial 18 finished with value: 0.8210762258843601 and parameters: {'n_estimators': 159, 'max_depth': 13, 'max_features': 'log2', 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8286956990495172.\n",
      "[I 2025-02-25 19:51:36,834] Trial 19 finished with value: 0.8228924336054888 and parameters: {'n_estimators': 223, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.8286956990495172.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beste Hyperparameter für Random Forest:\n",
      "{'n_estimators': 181, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
      "\n",
      "Optimierungsergebnisse:\n",
      "   Number of iterations  Iteration Number of Optimal Hyperparameters  \\\n",
      "0                    20                                           14   \n",
      "\n",
      "      Score  Time Elapsed (s)  \n",
      "0  0.828696        258.581924  \n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optimization of the RandomForest Hyperparameter\"\"\"\n",
    "\n",
    "    #Searchspace\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 250)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\"])\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10, step=2)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 4)\n",
    "\n",
    "    #Model\n",
    "    params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_features\": max_features,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"min_samples_split\": min_samples_split,\n",
    "        \"min_samples_leaf\": min_samples_leaf\n",
    "    }\n",
    "\n",
    "    model_rf_mod = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **params)\n",
    "\n",
    "    num_cols_mod = features_train_mod.select_dtypes(include=[\"int64\"]).columns\n",
    "    cat_cols_mod = features_train_mod.select_dtypes(include=[\"object\"]).columns \n",
    "\n",
    "    preprocessor_mod = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_cols_mod),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_mod)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    pipeline_mod = Pipeline([\n",
    "        (\"preprocessor\", preprocessor_mod),\n",
    "        (\"model\", model_rf_mod)\n",
    "    ])\n",
    "\n",
    "    score = cross_val_score(\n",
    "        estimator=pipeline_mod, \n",
    "        X=features_train_mod, \n",
    "        y=target_train, \n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=3,\n",
    "        n_jobs=1\n",
    "    ).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# create a study and setting a seed for reproduceability\n",
    "study = optuna.create_study(sampler=TPESampler(seed=42), direction='maximize')\n",
    "\n",
    "# perform hyperparameter tuning\n",
    "time_start = time.time()\n",
    "\n",
    "# starting optimization process with our defined function \n",
    "study.optimize(objective, n_trials=20)\n",
    "time_bayesian = time.time() - time_start\n",
    "\n",
    "# store result in a data frame \n",
    "values_bayesian = [\n",
    "    20, \n",
    "    study.best_trial.number, \n",
    "    study.best_trial.value, \n",
    "    time_bayesian\n",
    "]\n",
    "\n",
    "results_bayesian = pd.DataFrame([values_bayesian], columns=[\n",
    "    \"Number of iterations\", \n",
    "    \"Iteration Number of Optimal Hyperparameters\", \n",
    "    \"Score\", \n",
    "    \"Time Elapsed (s)\"\n",
    "])\n",
    "\n",
    "# best hyperparameter\n",
    "print(\"\\nBeste Hyperparameter für Random Forest:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "# show results\n",
    "print(\"\\nOptimierungsergebnisse:\")\n",
    "print(results_bayesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_mod = study.best_params\n",
    "\n",
    "model_rf_ba_mod = RandomForestClassifier(class_weight=\"balanced\", random_state=42, **best_params)\n",
    "pipeline_rf_ba_mod = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_mod),\n",
    "    (\"model\", model_rf_ba_mod)\n",
    "])\n",
    "\n",
    "pipeline_rf_ba_mod.fit(features_train_mod, target_train)\n",
    "target_pred_rf_ba_mod = pipeline_rf_ba_mod.predict(features_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>ROC-AUC-Male</th>\n",
       "      <th>ROC-AUC-Female</th>\n",
       "      <th>ROC-AUC-White</th>\n",
       "      <th>ROC-AUC-Non-White</th>\n",
       "      <th>EOD 'sex'</th>\n",
       "      <th>EOD 'race'</th>\n",
       "      <th>DI 'sex'</th>\n",
       "      <th>DI 'race'</th>\n",
       "      <th>DPD 'sex'</th>\n",
       "      <th>DPD 'race'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>57.488131</td>\n",
       "      <td>84.948980</td>\n",
       "      <td>68.571429</td>\n",
       "      <td>82.514935</td>\n",
       "      <td>79.150758</td>\n",
       "      <td>83.022660</td>\n",
       "      <td>81.738459</td>\n",
       "      <td>85.870827</td>\n",
       "      <td>0.223662</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.277424</td>\n",
       "      <td>0.375487</td>\n",
       "      <td>0.337677</td>\n",
       "      <td>0.237601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>62.120233</td>\n",
       "      <td>61.288265</td>\n",
       "      <td>61.701445</td>\n",
       "      <td>74.718956</td>\n",
       "      <td>73.625222</td>\n",
       "      <td>72.272830</td>\n",
       "      <td>74.576386</td>\n",
       "      <td>74.310595</td>\n",
       "      <td>0.128340</td>\n",
       "      <td>0.116829</td>\n",
       "      <td>0.334187</td>\n",
       "      <td>0.504326</td>\n",
       "      <td>0.202752</td>\n",
       "      <td>0.124805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>73.161486</td>\n",
       "      <td>61.543367</td>\n",
       "      <td>66.851403</td>\n",
       "      <td>77.192311</td>\n",
       "      <td>76.598644</td>\n",
       "      <td>74.563998</td>\n",
       "      <td>77.062118</td>\n",
       "      <td>76.245767</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.299828</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.184475</td>\n",
       "      <td>0.187295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestBaysian</th>\n",
       "      <td>56.068655</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>68.343711</td>\n",
       "      <td>82.880435</td>\n",
       "      <td>79.040246</td>\n",
       "      <td>82.998964</td>\n",
       "      <td>82.119979</td>\n",
       "      <td>85.885341</td>\n",
       "      <td>0.260354</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.251333</td>\n",
       "      <td>0.463706</td>\n",
       "      <td>0.373733</td>\n",
       "      <td>0.215170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modifizierter RandomForest</th>\n",
       "      <td>69.193989</td>\n",
       "      <td>64.604592</td>\n",
       "      <td>66.820580</td>\n",
       "      <td>77.742134</td>\n",
       "      <td>76.863478</td>\n",
       "      <td>74.408959</td>\n",
       "      <td>77.539705</td>\n",
       "      <td>76.567489</td>\n",
       "      <td>0.145436</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.276911</td>\n",
       "      <td>0.129771</td>\n",
       "      <td>0.213561</td>\n",
       "      <td>0.212885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modifizierter RandomForestBaysian</th>\n",
       "      <td>56.260229</td>\n",
       "      <td>87.691327</td>\n",
       "      <td>68.544367</td>\n",
       "      <td>83.036765</td>\n",
       "      <td>79.164099</td>\n",
       "      <td>83.306898</td>\n",
       "      <td>82.307254</td>\n",
       "      <td>85.626512</td>\n",
       "      <td>0.260908</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.249586</td>\n",
       "      <td>0.450931</td>\n",
       "      <td>0.374433</td>\n",
       "      <td>0.220296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   precision     recall         f1    ROC-AUC  \\\n",
       "LogisticRegression                 57.488131  84.948980  68.571429  82.514935   \n",
       "DecisionTree                       62.120233  61.288265  61.701445  74.718956   \n",
       "RandomForest                       73.161486  61.543367  66.851403  77.192311   \n",
       "RandomForestBaysian                56.068655  87.500000  68.343711  82.880435   \n",
       "Modifizierter RandomForest         69.193989  64.604592  66.820580  77.742134   \n",
       "Modifizierter RandomForestBaysian  56.260229  87.691327  68.544367  83.036765   \n",
       "\n",
       "                                   ROC-AUC-Male  ROC-AUC-Female  \\\n",
       "LogisticRegression                    79.150758       83.022660   \n",
       "DecisionTree                          73.625222       72.272830   \n",
       "RandomForest                          76.598644       74.563998   \n",
       "RandomForestBaysian                   79.040246       82.998964   \n",
       "Modifizierter RandomForest            76.863478       74.408959   \n",
       "Modifizierter RandomForestBaysian     79.164099       83.306898   \n",
       "\n",
       "                                   ROC-AUC-White  ROC-AUC-Non-White  \\\n",
       "LogisticRegression                     81.738459          85.870827   \n",
       "DecisionTree                           74.576386          74.310595   \n",
       "RandomForest                           77.062118          76.245767   \n",
       "RandomForestBaysian                    82.119979          85.885341   \n",
       "Modifizierter RandomForest             77.539705          76.567489   \n",
       "Modifizierter RandomForestBaysian      82.307254          85.626512   \n",
       "\n",
       "                                   EOD 'sex'  EOD 'race'  DI 'sex'  DI 'race'  \\\n",
       "LogisticRegression                  0.223662    0.571429  0.277424   0.375487   \n",
       "DecisionTree                        0.128340    0.116829  0.334187   0.504326   \n",
       "RandomForest                        0.109907    0.464286  0.299828   0.144932   \n",
       "RandomForestBaysian                 0.260354    0.428571  0.251333   0.463706   \n",
       "Modifizierter RandomForest          0.145436    0.464286  0.276911   0.129771   \n",
       "Modifizierter RandomForestBaysian   0.260908    0.285714  0.249586   0.450931   \n",
       "\n",
       "                                   DPD 'sex'  DPD 'race'  \n",
       "LogisticRegression                  0.337677    0.237601  \n",
       "DecisionTree                        0.202752    0.124805  \n",
       "RandomForest                        0.184475    0.187295  \n",
       "RandomForestBaysian                 0.373733    0.215170  \n",
       "Modifizierter RandomForest          0.213561    0.212885  \n",
       "Modifizierter RandomForestBaysian   0.374433    0.220296  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_target_list = [target_pred_log_base, target_pred_dt, target_pred_rf, target_pred_rf_ba, target_pred_rf_mod, target_pred_rf_ba_mod]\n",
    "model_name = [\"LogisticRegression\", \"DecisionTree\", \"RandomForest\", \"RandomForestBaysian\", \"Modifizierter RandomForest\", \"Modifizierter RandomForestBaysian\"]\n",
    "mod_qual = []\n",
    "\n",
    "for target in pred_target_list:\n",
    "    precision = precision_score(target_test, target)\n",
    "    recall = recall_score(target_test, target)\n",
    "    f1 = f1_score(target_test, target)\n",
    "    roc_auc = roc_auc_score(target_test, target)\n",
    "    \n",
    "    mask = features_test[\"sex\"] == 1\n",
    "    roc_auc_male = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"sex\"] == 0\n",
    "    roc_auc_female = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] == \"White\"\n",
    "    roc_auc_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] != \"White\"\n",
    "    roc_auc_Non_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "    eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "    di_sex = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"sex\"]\n",
    "    )\n",
    "    \n",
    "    di_race = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"race\"]\n",
    "    )\n",
    "\n",
    "    dp_diff_sex = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "    dp_diff_race = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"race\"])\n",
    "    \n",
    "    mod_qual.append({\n",
    "                    \"precision\": (precision*100), \"recall\": (recall*100), \"f1\":(f1*100), \"ROC-AUC\": (roc_auc*100),\n",
    "                    \"ROC-AUC-Male\": (roc_auc_male*100),\n",
    "                    \"ROC-AUC-Female\": (roc_auc_female*100),\n",
    "                    \"ROC-AUC-White\": (roc_auc_White*100),\n",
    "                    \"ROC-AUC-Non-White\": (roc_auc_Non_White*100),\n",
    "                    \"EOD 'sex'\": (eq_odds_diff_sex),\n",
    "                    \"EOD 'race'\": (eq_odds_diff_race),\n",
    "                    \"DI 'sex'\": (di_sex),\n",
    "                    \"DI 'race'\": (di_race),\n",
    "                    \"DPD 'sex'\": (dp_diff_sex),\n",
    "                    \"DPD 'race'\": (dp_diff_race)\n",
    "                    })\n",
    "    \n",
    "df_mod_qual = pd.DataFrame(mod_qual, index=model_name)\n",
    "df_mod_qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bewertung\n",
    "1. Wichtigste Erkenntnisse aus den Fairness-Metriken:\n",
    "- DecisionTree ist am fairsten für \"race\", hat aber die schlechteste ROC-AUC (74.71)\n",
    "- RandomForest ist am fairsten für \"sex\", zeigt aber eine starke Diskriminierung für \"race\"\n",
    "- Logistic Regression und Bayesian-Modelle sind die am stärksten diskriminierenden Modelle.\n",
    "- Der Modifizierte RandomForest bietet eine gute Balance zwischen Fairness und Performance.\n",
    "\n",
    "2. Abwägung zwischen Fairness und Performance\n",
    "- Höchste Performance: RandomForestBayesian (83.03 ROC-AUC), aber hohe Diskriminierung.\n",
    "- Fairstes Modell für \"race\": DecisionTree, aber schwache Performance.\n",
    "- Fairstes Modell für \"sex\": RandomForest.\n",
    "- Bester Kompromiss: Modifizierter RandomForest (gute Balance zwischen Fairness und Leistung).\n",
    "\n",
    "3. VWeiterführung:\n",
    "- Fainess-Korrekturen an dem optimierten RandomForest \n",
    "    - Reweighing (durch die Spalte \"fnlwgt\") bereits implementiert\n",
    "    - In-Processing-Techniken: Fainess Constraints \n",
    "    - Post-Processing: Fainess-Korrektur\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "\n",
    "# RandomForest mit einer Fairness-Beschränkung\n",
    "constraint = DemographicParity()  # Alternativ: EqualizedOdds() -> würde noch länger laufen\n",
    "fair_model_rf = ExponentiatedGradient(RandomForestClassifier(n_estimators=100, random_state=42), constraints=constraint)\n",
    "\n",
    "# Preprocessor\n",
    "X_train_processed = preprocessor.fit_transform(features_train)\n",
    "X_train_processed = X_train_processed.toarray()\n",
    "\n",
    "X_test_processed = preprocessor.transform(features_test)\n",
    "X_test_processed = X_test_processed.toarray()\n",
    "\n",
    "# Trainiere das Modell\n",
    "fair_model_rf.fit(X_train_processed, target_train, sensitive_features=features_train[[\"sex\", \"race\"]])\n",
    "\n",
    "# Vorhersagen\n",
    "target_pred_fair_rf = fair_model_rf.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistische Regression mit einer Fairness-Beschränkung\n",
    "constraint = DemographicParity()  # Alternativ: EqualizedOdds()\n",
    "fair_model_log = ExponentiatedGradient(LogisticRegression(max_iter=1000, random_state=42), constraints=constraint)\n",
    "\n",
    "# Preprocessor -> wurde bereits durchgeführt\n",
    "\n",
    "# Trainiere das Modell\n",
    "fair_model_log.fit(X_train_processed, target_train, sensitive_features=features_train[[\"sex\", \"race\"]])\n",
    "\n",
    "# Vorhersagen\n",
    "target_pred_fair_log = fair_model_log.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>ROC-AUC-Male</th>\n",
       "      <th>ROC-AUC-Female</th>\n",
       "      <th>ROC-AUC-White</th>\n",
       "      <th>ROC-AUC-Non-White</th>\n",
       "      <th>EOD 'sex'</th>\n",
       "      <th>EOD 'race'</th>\n",
       "      <th>DI 'sex'</th>\n",
       "      <th>DI 'race'</th>\n",
       "      <th>DPD 'sex'</th>\n",
       "      <th>DPD 'race'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>57.488131</td>\n",
       "      <td>84.948980</td>\n",
       "      <td>68.571429</td>\n",
       "      <td>82.514935</td>\n",
       "      <td>79.150758</td>\n",
       "      <td>83.022660</td>\n",
       "      <td>81.738459</td>\n",
       "      <td>85.870827</td>\n",
       "      <td>0.223662</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.277424</td>\n",
       "      <td>0.375487</td>\n",
       "      <td>0.337677</td>\n",
       "      <td>0.237601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Faire LogiticRegression</th>\n",
       "      <td>69.938650</td>\n",
       "      <td>50.892857</td>\n",
       "      <td>58.914729</td>\n",
       "      <td>71.978279</td>\n",
       "      <td>70.697588</td>\n",
       "      <td>82.882744</td>\n",
       "      <td>71.910166</td>\n",
       "      <td>74.129173</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>0.440313</td>\n",
       "      <td>0.838720</td>\n",
       "      <td>0.655668</td>\n",
       "      <td>0.029845</td>\n",
       "      <td>0.061065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>73.161486</td>\n",
       "      <td>61.543367</td>\n",
       "      <td>66.851403</td>\n",
       "      <td>77.192311</td>\n",
       "      <td>76.598644</td>\n",
       "      <td>74.563998</td>\n",
       "      <td>77.062118</td>\n",
       "      <td>76.245767</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.299828</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.184475</td>\n",
       "      <td>0.187295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestBaysian</th>\n",
       "      <td>56.068655</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>68.343711</td>\n",
       "      <td>82.880435</td>\n",
       "      <td>79.040246</td>\n",
       "      <td>82.998964</td>\n",
       "      <td>82.119979</td>\n",
       "      <td>85.885341</td>\n",
       "      <td>0.260354</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.251333</td>\n",
       "      <td>0.463706</td>\n",
       "      <td>0.373733</td>\n",
       "      <td>0.215170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairer RandomForest</th>\n",
       "      <td>55.323820</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>59.469027</td>\n",
       "      <td>73.912321</td>\n",
       "      <td>75.981960</td>\n",
       "      <td>70.606461</td>\n",
       "      <td>74.597517</td>\n",
       "      <td>68.594582</td>\n",
       "      <td>0.104836</td>\n",
       "      <td>0.363104</td>\n",
       "      <td>0.948742</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.061242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         precision     recall         f1    ROC-AUC  \\\n",
       "LogisticRegression       57.488131  84.948980  68.571429  82.514935   \n",
       "Faire LogiticRegression  69.938650  50.892857  58.914729  71.978279   \n",
       "RandomForest             73.161486  61.543367  66.851403  77.192311   \n",
       "RandomForestBaysian      56.068655  87.500000  68.343711  82.880435   \n",
       "Fairer RandomForest      55.323820  64.285714  59.469027  73.912321   \n",
       "\n",
       "                         ROC-AUC-Male  ROC-AUC-Female  ROC-AUC-White  \\\n",
       "LogisticRegression          79.150758       83.022660      81.738459   \n",
       "Faire LogiticRegression     70.697588       82.882744      71.910166   \n",
       "RandomForest                76.598644       74.563998      77.062118   \n",
       "RandomForestBaysian         79.040246       82.998964      82.119979   \n",
       "Fairer RandomForest         75.981960       70.606461      74.597517   \n",
       "\n",
       "                         ROC-AUC-Non-White  EOD 'sex'  EOD 'race'  DI 'sex'  \\\n",
       "LogisticRegression               85.870827   0.223662    0.571429  0.277424   \n",
       "Faire LogiticRegression          74.129173   0.275781    0.440313  0.838720   \n",
       "RandomForest                     76.245767   0.109907    0.464286  0.299828   \n",
       "RandomForestBaysian              85.885341   0.260354    0.428571  0.251333   \n",
       "Fairer RandomForest              68.594582   0.104836    0.363104  0.948742   \n",
       "\n",
       "                         DI 'race'  DPD 'sex'  DPD 'race'  \n",
       "LogisticRegression        0.375487   0.337677    0.237601  \n",
       "Faire LogiticRegression   0.655668   0.029845    0.061065  \n",
       "RandomForest              0.144932   0.184475    0.187295  \n",
       "RandomForestBaysian       0.463706   0.373733    0.215170  \n",
       "Fairer RandomForest       0.783951   0.014586    0.061242  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_target_list_fair = [target_pred_log_base, target_pred_fair_log, target_pred_rf, target_pred_rf_ba, target_pred_fair_rf]\n",
    "model_name = [\"LogisticRegression\", \"Faire LogiticRegression\", \"RandomForest\", \"RandomForestBaysian\", \"Fairer RandomForest\"]\n",
    "mod_qual = []\n",
    "\n",
    "for target in pred_target_list_fair:\n",
    "    precision = precision_score(target_test, target)\n",
    "    recall = recall_score(target_test, target)\n",
    "    f1 = f1_score(target_test, target)\n",
    "    roc_auc = roc_auc_score(target_test, target)\n",
    "    \n",
    "    mask = features_test[\"sex\"] == 1\n",
    "    roc_auc_male = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"sex\"] == 0\n",
    "    roc_auc_female = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] == \"White\"\n",
    "    roc_auc_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] != \"White\"\n",
    "    roc_auc_Non_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "    eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "    di_sex = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"sex\"]\n",
    "    )\n",
    "    \n",
    "    di_race = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"race\"]\n",
    "    )\n",
    "\n",
    "    dp_diff_sex = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "    dp_diff_race = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"race\"])\n",
    "    \n",
    "    mod_qual.append({\n",
    "                    \"precision\": (precision*100), \"recall\": (recall*100), \"f1\":(f1*100), \"ROC-AUC\": (roc_auc*100),\n",
    "                    \"ROC-AUC-Male\": (roc_auc_male*100),\n",
    "                    \"ROC-AUC-Female\": (roc_auc_female*100),\n",
    "                    \"ROC-AUC-White\": (roc_auc_White*100),\n",
    "                    \"ROC-AUC-Non-White\": (roc_auc_Non_White*100),\n",
    "                    \"EOD 'sex'\": (eq_odds_diff_sex),\n",
    "                    \"EOD 'race'\": (eq_odds_diff_race),\n",
    "                    \"DI 'sex'\": (di_sex),\n",
    "                    \"DI 'race'\": (di_race),\n",
    "                    \"DPD 'sex'\": (dp_diff_sex),\n",
    "                    \"DPD 'race'\": (dp_diff_race)\n",
    "                    })\n",
    "    \n",
    "df_mod_qual = pd.DataFrame(mod_qual, index=model_name)\n",
    "df_mod_qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung nach Fairness Constraints\n",
    "1. Fairness-Verbesserung\n",
    "- Logistische Regression\n",
    "    - EOD-Werte gesunken für \"race\", aber leicht gestiegen für \"sex\".\n",
    "    - Disparate Impact (DI) hat sich stark verbessert → von 0.277 auf 0.838 (für \"sex\") und 0.375 auf 0.655 (für \"race\").\n",
    "    - DPD-Werte sind stark gesunken, was bedeutet, dass das Modell jetzt deutlich fairere Vorhersageverteilungen macht.\n",
    "    FAZIT: Starke Verbesserung der Fairness, aber auf Kosten der Performance.\n",
    "- RandomForest\n",
    "    - OD-Werte haben sich verbessert (besonders für \"race\", von 0.464 auf 0.363).\n",
    "    - Disparate Impact (DI) ist fast perfekt für \"sex\" (0.9487) und stark verbessert für \"race\" (0.7839).\n",
    "    - DPD-Werte sind extrem gesunken, also kaum noch Unterschiede in den positiven Vorhersagen.\n",
    "    FAZIT: Beste Fairness-Verbesserung mit minimalem Performance-Verlust!\n",
    "\n",
    "2. Performance-Verlust durch Fairness-Optimierung\n",
    "- Logistic Regression:\n",
    "    - ROC-AUC ist stark gesunken von 82.51 auf 71.98 → Bedeutender Verlust an Modellqualität.\n",
    "    - Precision ist gestiegen, aber Recall ist stark gefallen → Das Modell ist nun sehr konservativ mit positiven Vorhersagen.\n",
    "    FAZIT: Starke Fairness-Verbesserung, aber das Modell ist insgesamt schwächer.\n",
    "\n",
    "- Random Forest:\n",
    "    - ROC-AUC hat sich nur leicht verschlechtert (77.19 → 73.91).\n",
    "    - Precision hat stark gelitten (73.16 → 55.32), aber Recall ist leicht gestiegen.\n",
    "    FAZIT: Besserer Trade-off zwischen Fairness und Leistung als Logistic Regression.\n",
    "\n",
    "Fairer Random Forest ist der beste Kompromiss zwischen Fairness und Modellqualität."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy nach Postprocessing: 0.7795178873023184\n"
     ]
    }
   ],
   "source": [
    "# Test, ob Postprocessing weiter die Fairness beeinflusst\n",
    "\n",
    "# Threshold Optimizer mit Demographic Parity\n",
    "postprocess_model = ThresholdOptimizer(\n",
    "    estimator=fair_model_rf,  \n",
    "    constraints=\"demographic_parity\",  # Alternativ: \"equalized_odds\"\n",
    "    prefit=True  # Modell ist schon trainiert\n",
    ")\n",
    "\n",
    "# Trainiere den Postprocessor\n",
    "postprocess_model.fit(X_train_processed, target_train, sensitive_features=features_train[[\"sex\", \"race\"]])\n",
    "\n",
    "# Berechne faire Vorhersagen\n",
    "target_pred_fair_rf_post = postprocess_model.predict(X_test_processed, sensitive_features=features_test[[\"sex\", \"race\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold Optimizer mit Demographic Parity\n",
    "postprocess_model_eq = ThresholdOptimizer(\n",
    "    estimator=fair_model_rf,  \n",
    "    constraints=\"equalized_odds\",  \n",
    "    prefit=True \n",
    ")\n",
    "\n",
    "# Trainiere den Postprocessor\n",
    "postprocess_model_eq.fit(X_train_processed, target_train, sensitive_features=features_train[[\"sex\", \"race\"]])\n",
    "\n",
    "# Berechne faire Vorhersagen\n",
    "target_pred_fair_rf_post_eq = postprocess_model.predict(X_test_processed, sensitive_features=features_test[[\"sex\", \"race\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>ROC-AUC-Male</th>\n",
       "      <th>ROC-AUC-Female</th>\n",
       "      <th>ROC-AUC-White</th>\n",
       "      <th>ROC-AUC-Non-White</th>\n",
       "      <th>EOD 'sex'</th>\n",
       "      <th>EOD 'race'</th>\n",
       "      <th>DI 'sex'</th>\n",
       "      <th>DI 'race'</th>\n",
       "      <th>DPD 'sex'</th>\n",
       "      <th>DPD 'race'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>73.161486</td>\n",
       "      <td>61.543367</td>\n",
       "      <td>66.851403</td>\n",
       "      <td>77.192311</td>\n",
       "      <td>76.598644</td>\n",
       "      <td>74.563998</td>\n",
       "      <td>77.062118</td>\n",
       "      <td>76.245767</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.299828</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.184475</td>\n",
       "      <td>0.187295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestBaysian</th>\n",
       "      <td>56.068655</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>68.343711</td>\n",
       "      <td>82.880435</td>\n",
       "      <td>79.040246</td>\n",
       "      <td>82.998964</td>\n",
       "      <td>82.119979</td>\n",
       "      <td>85.885341</td>\n",
       "      <td>0.260354</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.251333</td>\n",
       "      <td>0.463706</td>\n",
       "      <td>0.373733</td>\n",
       "      <td>0.215170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairer RandomForest</th>\n",
       "      <td>55.323820</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>59.469027</td>\n",
       "      <td>73.912321</td>\n",
       "      <td>75.981960</td>\n",
       "      <td>70.606461</td>\n",
       "      <td>74.597517</td>\n",
       "      <td>68.594582</td>\n",
       "      <td>0.104836</td>\n",
       "      <td>0.363104</td>\n",
       "      <td>0.948742</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.061242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairer RandomForest Postprocessing</th>\n",
       "      <td>53.514377</td>\n",
       "      <td>64.094388</td>\n",
       "      <td>58.328497</td>\n",
       "      <td>73.220096</td>\n",
       "      <td>75.908801</td>\n",
       "      <td>67.294562</td>\n",
       "      <td>73.917640</td>\n",
       "      <td>68.294630</td>\n",
       "      <td>0.118346</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.974887</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.007302</td>\n",
       "      <td>0.057957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fairer RandomForest Postprocessing_Eq</th>\n",
       "      <td>53.952991</td>\n",
       "      <td>64.413265</td>\n",
       "      <td>58.720930</td>\n",
       "      <td>73.490758</td>\n",
       "      <td>75.910265</td>\n",
       "      <td>69.419974</td>\n",
       "      <td>74.447442</td>\n",
       "      <td>66.315917</td>\n",
       "      <td>0.120303</td>\n",
       "      <td>0.223028</td>\n",
       "      <td>0.996289</td>\n",
       "      <td>0.739336</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.086888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       precision     recall         f1  \\\n",
       "RandomForest                           73.161486  61.543367  66.851403   \n",
       "RandomForestBaysian                    56.068655  87.500000  68.343711   \n",
       "Fairer RandomForest                    55.323820  64.285714  59.469027   \n",
       "Fairer RandomForest Postprocessing     53.514377  64.094388  58.328497   \n",
       "Fairer RandomForest Postprocessing_Eq  53.952991  64.413265  58.720930   \n",
       "\n",
       "                                         ROC-AUC  ROC-AUC-Male  \\\n",
       "RandomForest                           77.192311     76.598644   \n",
       "RandomForestBaysian                    82.880435     79.040246   \n",
       "Fairer RandomForest                    73.912321     75.981960   \n",
       "Fairer RandomForest Postprocessing     73.220096     75.908801   \n",
       "Fairer RandomForest Postprocessing_Eq  73.490758     75.910265   \n",
       "\n",
       "                                       ROC-AUC-Female  ROC-AUC-White  \\\n",
       "RandomForest                                74.563998      77.062118   \n",
       "RandomForestBaysian                         82.998964      82.119979   \n",
       "Fairer RandomForest                         70.606461      74.597517   \n",
       "Fairer RandomForest Postprocessing          67.294562      73.917640   \n",
       "Fairer RandomForest Postprocessing_Eq       69.419974      74.447442   \n",
       "\n",
       "                                       ROC-AUC-Non-White  EOD 'sex'  \\\n",
       "RandomForest                                   76.245767   0.109907   \n",
       "RandomForestBaysian                            85.885341   0.260354   \n",
       "Fairer RandomForest                            68.594582   0.104836   \n",
       "Fairer RandomForest Postprocessing             68.294630   0.118346   \n",
       "Fairer RandomForest Postprocessing_Eq          66.315917   0.120303   \n",
       "\n",
       "                                       EOD 'race'  DI 'sex'  DI 'race'  \\\n",
       "RandomForest                             0.464286  0.299828   0.144932   \n",
       "RandomForestBaysian                      0.428571  0.251333   0.463706   \n",
       "Fairer RandomForest                      0.363104  0.948742   0.783951   \n",
       "Fairer RandomForest Postprocessing       0.714286  0.974887   0.804233   \n",
       "Fairer RandomForest Postprocessing_Eq    0.223028  0.996289   0.739336   \n",
       "\n",
       "                                       DPD 'sex'  DPD 'race'  \n",
       "RandomForest                            0.184475    0.187295  \n",
       "RandomForestBaysian                     0.373733    0.215170  \n",
       "Fairer RandomForest                     0.014586    0.061242  \n",
       "Fairer RandomForest Postprocessing      0.007302    0.057957  \n",
       "Fairer RandomForest Postprocessing_Eq   0.001068    0.086888  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_target_list_fair = [target_pred_rf, target_pred_rf_ba, target_pred_fair_rf, target_pred_fair_rf_post, target_pred_fair_rf_post_eq]\n",
    "model_name = [\"RandomForest\", \"RandomForestBaysian\", \"Fairer RandomForest\", \"Fairer RandomForest Postprocessing\", \"Fairer RandomForest Postprocessing_Eq\"]\n",
    "mod_qual = []\n",
    "\n",
    "for target in pred_target_list_fair:\n",
    "    precision = precision_score(target_test, target)\n",
    "    recall = recall_score(target_test, target)\n",
    "    f1 = f1_score(target_test, target)\n",
    "    roc_auc = roc_auc_score(target_test, target)\n",
    "    \n",
    "    mask = features_test[\"sex\"] == 1\n",
    "    roc_auc_male = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"sex\"] == 0\n",
    "    roc_auc_female = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] == \"White\"\n",
    "    roc_auc_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    mask = features_test[\"race\"] != \"White\"\n",
    "    roc_auc_Non_White = roc_auc_score(target_test[mask], target[mask])\n",
    "\n",
    "    eq_odds_diff_sex = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"sex\"])\n",
    "\n",
    "    eq_odds_diff_race = equalized_odds_difference(y_true = target_test, \n",
    "                                               y_pred = target,\n",
    "                                           sensitive_features= features_test[\"race\"])\n",
    "    di_sex = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"sex\"]\n",
    "    )\n",
    "    \n",
    "    di_race = demographic_parity_ratio(\n",
    "        y_pred = target,\n",
    "        y_true = target_test,\n",
    "        sensitive_features=features_test[\"race\"]\n",
    "    )\n",
    "\n",
    "    dp_diff_sex = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"sex\"])\n",
    "                                     \n",
    "    dp_diff_race = demographic_parity_difference(\n",
    "        y_pred=target, \n",
    "        y_true=target_test,\n",
    "        sensitive_features=features_test[\"race\"])\n",
    "    \n",
    "    mod_qual.append({\n",
    "                    \"precision\": (precision*100), \"recall\": (recall*100), \"f1\":(f1*100), \"ROC-AUC\": (roc_auc*100),\n",
    "                    \"ROC-AUC-Male\": (roc_auc_male*100),\n",
    "                    \"ROC-AUC-Female\": (roc_auc_female*100),\n",
    "                    \"ROC-AUC-White\": (roc_auc_White*100),\n",
    "                    \"ROC-AUC-Non-White\": (roc_auc_Non_White*100),\n",
    "                    \"EOD 'sex'\": (eq_odds_diff_sex),\n",
    "                    \"EOD 'race'\": (eq_odds_diff_race),\n",
    "                    \"DI 'sex'\": (di_sex),\n",
    "                    \"DI 'race'\": (di_race),\n",
    "                    \"DPD 'sex'\": (dp_diff_sex),\n",
    "                    \"DPD 'race'\": (dp_diff_race)\n",
    "                    })\n",
    "    \n",
    "df_mod_qual = pd.DataFrame(mod_qual, index=model_name)\n",
    "df_mod_qual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bewertung\n",
    "Equalized Odds ist die beste Fairness-Korrektur für \"race\" (EOD stark verbessert von 0.7143 auf 0.2230).\n",
    "Hinsichtlich Performance nur geringe Einbuße durch Postprocessing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
